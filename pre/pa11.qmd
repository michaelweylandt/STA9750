---
pa_num: 11
pa_title: "Introduction to Statistical Modeling in `R`"
---

```{r}
#| echo: false
#| warning: false
#| message: false
library(tidyverse)
NUMBER <- as.integer(rmarkdown::metadata$pa_num)
due_date_str <- read_csv("key_dates.csv") |> 
    filter(`Course Element` == "Pre-Assignments", 
           `Item Number` == NUMBER, 
           str_detect(Details, "Due")) |> 
    mutate(dt = parse_date_time(paste(Date, Time), "%Y-%m-%d %H:%M%p")) |>
    pull(dt) |>
    format("%Y-%m-%d (%A) at %I:%M%P")
```

**Due Date**: `{r} due_date_str`

**Submission**: [CUNY Brightspace](https://brightspace.cuny.edu/)

In our final week, we are going to look into predictive modeling (*i.e.*,
black-box machine learning) with `R`. Specifically, we are going to introduce
the `tidymodels` framework in class, which provides a consistent toolkit for
interacting with a wide range of modeling tools. Before we get to `tidymodels`,
it will be useful to remember the basic modeling functionality in "basic `R`".

You have hopefully seen some of this material previously in your STA 9708 or 
STA 9700 courses. If you haven't, the mathematical details of what are happening
here are not important for our purposes and I'd encourage you to focus on the 
code and user-interface instead. 

## Statistical Tests in `R`

When studying `dplyr`, we performed many comparisons between penguin groups: 
*e.g.*, 

```{r}
#| message: false
library(tidyverse)

penguins |>
    drop_na() |>
    group_by(species) |> 
    summarize(mean_body_mass = mean(body_mass))
```

While we can compute the difference in averages,[^paired] we may reasonably ask
whether this difference rises to the level of statistical significance: that is,
is there enough evidence to say that there is a _systematic_ difference, or could
the difference be plausibly due to getting a few extra-chunky penguins? 

This type of statistical question is a deep and fundamental part of statistics,
generally known as _inference_, and it is a topic you will cover at great length
in your other courses. In this note, we simply focus on the computational steps
needed to perform tests. 

We will implement two of the most widely used types of tests here, though
many others can be implemented using the same framework. 

For each of these, we will make use of the `infer` package, though base `R`
equivalents are available. 

- A $t$-test
- A proportion test

### $t$-Test

Perhaps the most fundamental task in statistics is to ask whether two groups are
systematically different: this is the world of _two-sample testing_. 
'Systematically different' is a somewhat slippery term requiring more 
more specificity: if we interpret it to mean "having different means", then we
arrive at so-called $t$-tests: tests of whether two groups have different means. 

$t$-tests are typically performed under the assumption that each observation
is normally distributed around its groups respective mean. This assumption, like
most normality assumptions, is impossible to verify, but the magic of statistics
is that -- with enough data in conditions that aren't too terrible[^assumptions]
-- this is often a reasonable assumption to make. When we assume normality, the
distribution of the estimated difference in means divided by the estimated 
standard deviation follows a $t$-distribution, giving this test its name. 

With the `infer` package, this type of test is implemented with the `t_test`
function.[^baseR] Like most `tidyverse` functions, the first argument to this
function is a data frame. The second argument is a _formula_: we haven't done
much with formulas to this point, but you might remember them from `facet_grid`
in `ggplot2`. 

A formula is an expression with a variable name on each side separated by a 
`~`.[^typing] Conventionally, the variable on the left-hand side is the
_response_ and the variable on the right-hand side is the _explanatory_ 
variable. In a $t$-test, the response is the quantity we care about, while the
explanatory variable is the group identifier.[^indep] So, for our beloved
penguins, if we want to see if males weigh more than females, we would 
use the formula: 

```{r}
#| eval: false
body_mass ~ sex
```

This gives us: 

```{r}
library(infer)
penguins |> t_test(body_mass ~ sex)
```

Note the `warning` message here: we are looking at the difference in groups, 
but we have not said which groups or in what order to compare them. Following
the text of the `warning`, it is a good idea to specify the order of the 
comparisons: 

```{r}
library(infer)
penguins |> t_test(body_mass ~ sex, order=c("male", "female"))
```

By specifing the order in this manner, we indicate that we are looking at the
_average male body mass_ minus the _average female body mass_. As such, most
of our results are flipped in sign from what we saw before. 

Let's look at the columns of our result: 

- `estimate`: this is our best guess ("point estimate") of the inter-group 
  difference
- `lower_ci` and `upper_ci`: these are the lower and upper end points of a 
  confidence interval for our estimate. By default, these are set at the 
  conventional 95% level, but this can be changed by supplying the `conf_level`
  argument. (Test yourself: if we set `conf_level=0.9` instead, what would happen
  to these two values?)
- `p_value`: This is a $p$-value, indicating the strength of evidence against 
  the null hypothesis that the averages of the two groups are equal. Smaller 
  $p$-values indicate more confidence that there is a systematic difference.
- `alternative`: This is honestly a bit odd, but functionally, it is an indirect
  way of specifying the null hypothesis tested. Here, the `two.sided` alternative,
  indicates that we tested a null of equality. If a directional alternative was
  provided (*e.g.*, `"greater"`), we would have tested against a null of 
  "less than or equal".[^alternative]

[^assumptions]: You should be a bit unsatisfied with "enough" and 
"not too terrible": these terms have more precise definitions, but they aren't in
our scope here. 

[^baseR]: The `t_test` function is a thin wrapper around the `t.test` function
provided to us by base `R`. The `infer` version has the nice property of returning
its results in a data frame, rather than a more obscure object type, but the
specific values returned are equal, so it's fine to use `t.test` instead. 

[^paired]: Not the _average difference_ as this data has no paired structure.

[^typing]: On most US keyboards, the `~` character can be found just above the 
`tab` key on the right hand side, and can be typed by holding down `shift` and
hitting the ``` ` ``` key.

[^indep]: You may have heard these variables referred to as the _independent_
and _dependent_ variables in other contexts. This terminology is absurd. In 
statistics, dependence is a symmetric relationship: $Y$ depends on $X$, then
$X$ depends on $Y$; and if $Y$ is independent of $X$, then $X$ is independent of
$Y$. Almost all of our methods are looking for some relationship between two
variables, so *a priori* calling one of them "independent" is just silly.

[^alternative]: It's conventional to specify the alternative instead of the null,
but if you recall your introductory courses, we really only test _against the null_, 
never _for the alternative_ so I find this to be a strange design choice.

The use of a `data.frame` here means that `infer` plays nicely with the tools
we have been using all semester long. For instance, we might question whether
all penguin species have an inter-sex difference: to test this, we split our
data into three parts and test them separately: 

```{r}
penguins |>
    group_by(species) |>
    nest() |>
    mutate(test_results = map(data, t_test, body_mass ~ sex, order=c("male", "female"))) |>
    unnest(test_results) |>
    arrange(desc(estimate))
```

Here, we see that Gentoos, being the largest penguins in our data, exhibit the
largest sex difference. This pattern can be very useful for testing sub-group
differences, though you should take at least a bit of care to avoid issues with
multiplicity corrections: 

![From XKCD #882](https://imgs.xkcd.com/comics/significant.png)

This structure plays particularly nicely with
`ggplot2` for visualizing differences: 

```{r}
penguins |>
    group_by(species) |>
    nest() |>
    mutate(test_results = map(data, t_test, body_mass ~ sex, order=c("male", "female"))) |>
    unnest(test_results) |>
    ggplot(aes(x=species, 
               y=estimate, 
               ymax=upper_ci, 
               ymin=lower_ci)) + 
        geom_point(size=4) + 
        geom_errorbar() + 
        xlab("Species") + 
        ylab("Estimated Sex Difference in Mean Body Mass") + 
        theme_bw()
```

### Proportion Tests

The `prop_test` function extends this paradigm to the case where the _response_ 
is a binary variable. This analysis is conceptually quite similar to a $t$-test,
but the mathematical details are based on a binomial distribution, not a normal
distribution. 

```{r}
penguins |> 
    drop_na() |>
    mutate(is_male = (sex == "male"), 
           is_gentoo = (species == "Gentoo")) |>
    prop_test(is_male ~ is_gentoo, order=c("TRUE", "FALSE"))
```

Notice here that we constructed our binary variables (`is_male`, `is_gentoo`)
manually. In theory, you can pass categorical variables to `prop_test` directly
and it will binarize them for you, but I find that behavior a bit too fragile. 

In both of these tests, we can instead perform a "one-sample" test, by not specifying
an explanatory variable and instead passing `NULL`

```{r}
penguins |> 
    mutate(is_male = (sex == "male")) |>
    prop_test(is_male ~ NULL, order=c("TRUE", "FALSE"))
```

Here, as the message suggests, we are testing against a null that the population
rate is 50% (equal male and female). We can specify `p` for other nulls: 

```{r}
penguins |> 
    mutate(is_male = (sex == "male")) |>
    prop_test(is_male ~ NULL, order=c("TRUE", "FALSE"), 
              p=0.6666)
```

So (unsurprisingly), we can say with high-confidence that there are not twice
as many male penguins as females in our sample. 

## Linear Models in `R`

Another important task for which `R` is well suited is the fitting and usage
of statistical models. As noted above, we will consider this topic in detail in
class, but it is worth being familiar with the basic tool for fitting linear models
in `R`, the `lm` function. 

The `tidymodels` package includes the `ames` data set, which records 82 variables
about 2,930 properties sold in Ames, Iowa. Clearly, predicting the sale price
of these properties is of significant interest, but with so many variables of 
different types, this is a non-trivial modeling challenges: 

```{r}
#| message: false
library(tidyverse)
library(tidymodels)

glimpse(ames)
```

As always, we start by visualizing the data: 

```{r}
ggplot(ames, 
       aes(x=Sale_Price)) + 
    geom_histogram() + 
    theme_bw() + 
    xlab("Sale Price (US Dollars)") + 
    ylab("Number of Homes Sold")
```

A quick analysis of the response variable (`Sale_Price`) suggests that a 
log-transformation might be helpful, but we won't worry about that in this. 

(Not all methods require this, and skewness in $y$ alone does not guarantee a 
transformation is needed - the skewness may actually reflect a skewness in 
an underlying predictor, not in the unmodeled noise response - but it at least 
flags it as something we may want to consider.)

```{r}
ggplot(ames, 
       aes(x=Sale_Price)) + 
    geom_histogram() + 
    theme_bw() + 
    scale_x_log10() + 
    xlab("Sale Price (US Dollars) [Log-Scale]") + 
    ylab("Number of Homes Sold")
```

In your regression course, you might have already seen `R`'s built-in support for
linear models via the `lm` function. The `lm` function generally takes two 
arguments: 

- A `formula`, specifying the model to be fit
- A `data` argument, specifying the data used to fit the model

For this data, a simple model might predict the sale price using the size
of the slot on which the house sits: 

```{r}
lm(Sale_Price ~ Lot_Area, data=ames)
```


We see here several useful behaviors: 

- `lm` automatically dropped unused variables
- An intercept was included by default

In this formula specification, as with the tests above, the left-hand side 
denotes the response and anything on the right-hand side is used to specify 
predictors. Unlike tests, it is simple to add more features to a linear model. 
In fact, all we need to do is to 'add' them to the right hand side:

```{r}
lm(Sale_Price ~ Lot_Area + First_Flr_SF + Second_Flr_SF, data=ames)
```

If we add in a categorical (`factor`) variable, `lm` is also smart enough to
handle this automatically for us.[^contrast]

```{r}
lm(Sale_Price ~ Lot_Area + First_Flr_SF + Second_Flr_SF + Central_Air, data=ames)
```

Note that, unlike the numerical features we used before, you'll see that a 
new variable is created `Central_AirY` that is a constant offset effect of having
central A/C in a home.

So the formula interface `lm` does quite a lot of good for us! And `R` provides
additional functionality for working with the model after we fit it: 

```{r}
ames_lm <- lm(Sale_Price ~ Lot_Area + First_Flr_SF + Second_Flr_SF + Central_Air, 
              data=ames)

predict(ames_lm)
```

When applied to a fitted linear model, the `predict` function will automatically
provide predicted values ($\hat{y}$) for the data originally used to fit the
model. These training or in-sample predictions are somewhat useful and, if we
had a second data set, we could use the `newdata` argument to get similar 
'test set' or 'out-of-sample' predictions which would provide us a more nuanced
view of model accuracy. 

If we want to work with this model in more detail, the `broom` package provides
useful functionality for `tidyverse`-type manipulation: 

```{r}
library(broom)

glance(ames_lm)
```

Here, we see that the `glance` function provides the usual 'model-level' statistics
that can be used to assess how effective the model is. Perhaps the most important
ones here are the `r.squared` value, indicating we capture about 60% of variability
with this model, and the `sigma` value indicating that our predictions are typically
off by about $50,000. 

The `tidy` function gives us information about specific coefficients: 

```{r}
tidy(ames_lm)
```

Probably the most useful column here is the `estimate` column, which provides the
estimated regression coefficients. 

We will have much more to say about these types of manipulations in class. 


[^contrast]: The specifics of mapping a categorical variable to a numerical
model like linear regression are beyond what we talk about in this course, but
surprisingly non-trivial. Ask your regression professor about `contrasts` or
`encodings`. 


