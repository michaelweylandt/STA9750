---
session: "`r session <- 13; session`"
class_date:
  "`r library(tidyverse); 
    tuesday_date <- read_csv('key_dates_tuesday.csv', name_repair='universal') |>
    filter(Course.Element == 'Class Session', 
           Item.Number == session) |>
    pull(Date) |> format('%a %Y-%m-%d'); 
    thursday_date <- read_csv('key_dates_thursday.csv', name_repair='universal') |>
    filter(Course.Element == 'Class Session', 
           Item.Number == session) |>
    pull(Date) |> format('%a %Y-%m-%d'); 
    paste(c(tuesday_date, thursday_date), collapse=' <br>')`"
---

{{< include _setup.qmd >}}

# Agenda

## Today

- Administrative Business
- Brief Review: Statistical Modeling
- New Material: Predictive Modeling
- Wrap Up and Looking Ahead

## Orientation

- Communicating Results (`quarto`)  ✅
- `R` Basics  ✅
- Data Manipulation in `R`  ✅
- Data Visualization in `R`  ✅
- Getting Data into `R`
- Statistical Modeling in `R`⬅️
  - Classical Statistical Models (`lm`, `cor`, `t.test`)
  - Modern Predictive Models (`tidymodels`)
  
# Administrative Business

## {{< var course.short >}} Mini-Project #04 {.smaller}

**Congratulations! Done with Mini-Projects!**

. . . 

![](https://mcg219.github.io/STA9750-2025-SPRING/mp04_files/figure-html/shift-map-1.png){height=20%}

(h/t `@mcg219`)

## {{< var course.short >}} Mini-Project #04

- Peer feedback assignments sent this morning
- Feedback due in ~ 1 week

. . . 


Pay attention to [the rubric](../miniprojects/mini04.html#rubric)

Recall reduced assignment scope / additional extra credit!


## Week `r session` Pre-Assignment

No more pre-assignments!

. . . 

Thank you for these!

## Course Feedback

Reflection on course: 

  - How far have you come?
  - What have you learned? 
  - What was helpful? What was unhelpful? 
  
> [My (anonymous) feedback survey](https://baruch.az1.qualtrics.com/jfe/form/SV_9uyZ4YFsrcRRPIG)

This is *in addition* to the Baruch central course assesments. 

## Course Feedback

Used to improve future course offerings. Previous changes:

- Added a second round of project feedback
  - Help students "scope" projects suitably
- More _applied analytics_ than _programming exercises_ in HW
  - Other programming resources already online; 
  - Many students have prior experience (Python, SQL)
  - More interest in *Analytics* than Software Engineering
- Added GitHub and Portfolio Construction
  - Give students *evidence of skills* to share with employers

## Course Feedback

Plans for future improvement: 

- (Slightly) limit scope of MPs
- Extra Credit for in-class engagement
- Move MP deadlines a bit earlier to give more time for final presentations

Other thoughts welcome!

## Grading

Returned:

- MP#03 Grades ✅
- MP#03 Meta-Review Grades ✅

I still owe you:

- MP#02 Meta-Review Re-Grades
- Re-Grade Queue (Brightspace)

## Course Support

- Synchronous
  - Office Hours 2x / week
    - MW Office Hours on **Tuesdays** + **Thursday**
- Asynchronous
  - Piazza ($\approx 20$ minute average response time)
  
No Office Hours after end of classes

- Still available on Piazza, but traveling so a bit slower

## Course Project

- Proposals ✅
- Check-In ✅
- [Final Presentation](https://michael-weylandt.com/STA9750/project.html#final-presentations)
- Final Reports
  - [Group](https://michael-weylandt.com/STA9750/project.html#final-summary-report)
  - [Individual](https://michael-weylandt.com/STA9750/project.html#final-individual-report)

## Final Presentation {.smaller}

Next week! Review [the Rubric](https://michael-weylandt.com/STA9750/project.html#final-presentations)!

- Overarching Question
- Motivation and Context: Why are you doing *this project*? 
- Prior Art: What have others done *in this space*? What gap are you filling?
- Data Used: What and why? "SWOT" it
- Specific Questions: What questions and how do they tie back?
- Results of Specific
- Implications for Overarching
- Next Steps / Future Work

*Non-Technical* Presentation - You're a "consultant" asked by a client to investigate

## Final Reports

Group **and** Individual Reports 

- Submitted via GitHub **and** Brightspace
- Everyone submit a separate link to group report

Deadline extended to the day of the semester

. . . 

**No late work accepted** (I have to submit grades 3 days later!)

## Project Peer Feedback

New peer feeback mechanism (feedback welcome!)

- You have 100 points *to allocate to teammates*

Can't assign points to yourself

. . . 

**Additionally**,  8 optional qualitative questions (Brightspace) for *peer evaluation* 

Submit a copy for *each* teammate - I will anonymize to give advice

- Due on same day as reports

. . . 

If you don't submit, you won't receive any points

## Final Project Grading

Rubric is set _high_ to give me flexibility to reward teams
that take on big challenges

Hard rubric => Grades are curved generously 

. . . 

Multiple paths to success 

If your project is "easy" on an element (data import
in particular), that's great! Don't spend the effort 
over-complicating things. Effort is better spent elsewhere

# Review: Statistical Modeling in `R`

## Formula Notation

`R` was designed for statistical analysis (originally called `S`)

. . . 

Major contributions

- `data.frame` / tidy structure
- Formula language ("Wilkinson-Rogers notation")

## Formula Notation

In `R`, a `formula` is a special object defined by a `~`

. . . 

Most common structure

> `y ~ x1 + x2`

Predict variable `y` using `x1` and `x2`

. . . 

- Modern `R` uses formulas in many other contexts
- Various extensions provided by packages

## Modeling Functions

Basic modeling function: `lm` (_linear model_)

```{r}
#| echo: true
lm(body_mass ~ flipper_len, data=penguins)
```


## Modeling Functions

```{r}
lm(body_mass ~ flipper_len, data=penguins)
```

- Provide model (`formula`) and data (`data.frame`) instead of $X, y$
- By default automatically includes an intercept term

## Modeling Functions

```{r}
lm(body_mass ~ flipper_len + species, data=penguins)
```

Automatically: 

- Encodes categorical (`factor`) variables
  - `?C` for details
- Removes extra / redundant columns


## Modeling Functions

```{r}
lm(body_mass ~ flipper_len*bill_dep, data=penguins)
```

- `*` creates both 'main' effects and interactions


## Modeling Functions

```{r}
lm(body_mass ~ flipper_len*species, data=penguins)
```

- `*` of continuous and categorical creates ANCOVA

## Modeling Functions 

Many extensions

```{r}
#| echo: true
library(mgcv)
gam(body_mass ~ s(flipper_len) + s(bill_dep, by=species), data=penguins)
```
Fits a *mixed-effect non-linear regression*

## Accessors

Helper functions to access fitted models: 

```{r}
#| echo: true
m <- lm(body_mass ~ flipper_len*bill_dep + species, data=penguins)
coef(m)
```

## Accessors

```{r}
#| echo: true
summary(m)
```

## Accessors

In-sample / training prediction: 

```{r}
#| echo: true
predict(m)
```

## Accessors

Out-of-sample / test prediction:

```{r}
#| echo: true
toppenguins <- penguins |> slice_max(body_mass, n=10)
predict(m, newdata=toppenguins)
```

## Accessors

For just `lm`: 

```{r}
#| echo: true
methods(class="lm")
```

Even more for other models

# New Material: Predictive Modeling in `tidymodels`

## Agenda

- Predictive Modeling with `tidymodels`

Adapted from [Case Study](https://www.tidymodels.org/start/case-study/)

## `tidymodels`

Strength of `R`: 
 
- Thousands of authors contributing packages to CRAN

. . . 

Weakness of `R`: 

- Thousands of authors contributing *slightly incompatible* packages to CRAN

. . . 

No two modeling packages have _exactly_ the same API. Makes 
changing between interfaces cumbersome

## `tidymodels`

`tidymodels` attemps to provide a _uniform_ interface
to a wide variety of _predictive_ Machine Learning tools

Advantages: 

- Easy to swap out different algorithms to find the best

Disadvantages: 

- Harder to take advantage of the strengths of each approach

. . . 

I have dedicated my academic life to the differences in these
methods, but 99% of the time, "black-box" prediction is good
enough. In STA 9890, we get into the weeds - not here.

## ML vs Statistical Pipelines

Statistics / Data Science: 

- Find the model that _fits_ the data best
- Model should capture all important data features
- _Interpretability_ 
- History: Grounded in lab sciences where experiments are
  expensive and data is limited 
  
## ML vs Statistical Pipelines

Machine Learning: 

- Find the model that _predicts_ the data best
- No "perfect" model - just the best one we've found so far
- Black-box techniques are great, _if effective_
- History: Silicon Valley "at scale"

Validation based on _of-of-sample_ or _test_ predictions

## Validating Predictive Power

How to check whether a model _predicts_ well?

. . . 

Need more data! But where to get more data? 

- Actually get more data (hard, expensive, slow)
- Split data into parts - test/training split
- Cross-Validation
- Resampling

. . . 

Today, we'll primarily use a combination: **Test/Train** split & **Cross-Validation**!

## Cross-Validation

![](https://scikit-learn.org/1.5/_images/grid_search_cross_validation.png)

Cross-Validation is done on the *estimator*, not the fitted algorithm

## `tidymodels`

`tidymodels` workflow: 

- Initial Split
- Pre-Process
- Fit (*many*) models
- Select best
- Refit
- Test Set Assessment

`tidymodels` is _very_ punny, so a bit hard to tell which step is which...

## Acquire Data

```{r}
#| echo: true
library(tidymodels); library(readr)

hotels <- 
  read_csv("https://tidymodels.org/start/case-study/hotels.csv") |>
  mutate(across(where(is.character), as.factor))

glimpse(hotels)
```

## Initial Split

```{r}
#| echo: true
#| eval: true
# Stratified sampling to ensure balance
splits      <- initial_split(hotels, 
                             strata = children)

hotel_train <- training(splits)
hotel_test  <- testing(splits)

hotel_train
```

## Pre-Process {.scrollable}

```{r}
library(recipes)
```

```{r}
#| eval: true
#| echo: true
#| message: true
holidays <- c("AllSouls", "AshWednesday", "ChristmasEve", "Easter", 
              "ChristmasDay", "GoodFriday", "NewYearsDay", "PalmSunday")

lr_recipe <- 
  recipe(children ~ ., data = hotels) |> 
  step_date(arrival_date) |> 
  step_holiday(arrival_date, holidays = holidays) |> 
  step_rm(arrival_date) |> 
  step_dummy(all_nominal_predictors()) |> 
  step_zv(all_predictors()) |> 
  step_normalize(all_predictors())

lr_recipe
```

## Fit Models

```{r}
#| eval: true
#| echo: true
lr_model <- 
  logistic_reg(penalty = tune(), mixture = 1) |> 
  set_engine("glmnet")

lr_model
```

## Select Best

Find a _grid_ of parameters 

```{r}
#| eval: true
#| echo: true
lr_reg_grid <- data.frame(penalty = 10^seq(-4, -1, length.out = 30))
```

Perform CV splits: 

```{r}
#| eval: true
#| echo: true
lr_folds <- vfold_cv(hotel_train, v = 5)
```

## Select Best

Define a *workflow*: 

```{r}
#| eval: true
#| echo: true
lr_workflow <-  
  workflow() |> 
  add_model(lr_model) |> 
  add_recipe(lr_recipe)
```

Fit workflow to a grid of parameters: 

```{r}
#| eval: true
#| echo: true
#| cache: true
lr_results <- 
  lr_workflow |> 
  tune_grid(grid = lr_reg_grid,
            control = control_grid(save_pred = TRUE, 
                                   save_workflow=TRUE),
            resamples = lr_folds,
            metrics = metric_set(roc_auc))
```

## Select Best

Visual examination

```{r}
#| eval: true
#| echo: true
#| cache: true
lr_results |> 
  collect_metrics() |> 
  ggplot(aes(x = penalty, y = mean)) + 
  geom_point() + 
  geom_line() + 
  ylab("Area under the ROC Curve") +
  scale_x_log10(labels = scales::label_number())
```

## Select Best

```{r}
#| eval: true
#| echo: true
lr_results |> show_best()
lr_best <- lr_results |> select_best()
lr_best
```


## Refit Best Model

```{r}
#| eval: true
#| echo: true
lr_best_fit <- lr_results |> fit_best()
lr_best_fit
```

## Test Set Assessment

```{r}
#| eval: true
#| echo: true
predict(lr_best_fit, hotel_test)
```

```{r}
#| echo: true
#| eval: true
augment(lr_best_fit, hotel_test)
```

## Exercise

Work through the _random forest_ components of [https://www.tidymodels.org/start/case-study](https://www.tidymodels.org/start/case-study)

You'll need to work through the data import elements as well

## Other `tidymodels` tools

- Model Stacking
- Probabilistic Predictions
- Uncertainty Bounds (Conformal Inference)
- Multilevel (Mixed-Effect) Models
- Fairness Audits

## More Reading

[https://www.tidymodels.org/start/](https://www.tidymodels.org/start/)

