#!/usr/bin/env python

# Standard Library
from collections import defaultdict, namedtuple
from functools import cache
from datetime import datetime
from glob import glob
import json
import math
from math import nan
import os
import os.path as op
from pathlib import Path
from statistics import median
import subprocess
import random
import re
import webbrowser
from copy import deepcopy as dcopy
from pprint import pformat

# PyPI Modules - Nothing here is too exotic, so not worrying about
# environment management / versioning for now
from bs4 import BeautifulSoup as BS
import click
from jinja2 import Environment, FileSystemLoader, select_autoescape
import numpy as np
import pandas as pd
import requests as r
from requests.compat import urljoin, quote, quote_plus
from yaml import safe_load as yaml_load
from pandas.api.types import is_list_like

Issue = namedtuple(
    "Issue", ["title", "number", "html_url", "body", "state", "opened_by"]
)

Comment = namedtuple("Comment", ["commenter", "text", "ctime", "url"])

class PeerFeedback:
    _template_url = "https://michael-weylandt.com/STA9750/miniprojects.html"
    
    resp = r.get(_template_url)
        
    if not resp.ok:
        raise click.ClickException("Could not download peer feedback template")
        
    template = BS(resp.text, features="lxml").\
        find(id="peer-feedback-template").\
        text.strip()
    
    template = re.sub("\s*\n", "\\\\s*\n", template).\
        replace("OPTIONAL TEXT", "(.*)").\
        replace("NN", "(\\d+)(?:/10)?").\
        replace("TEXT TEXT TEXT", "(.*)")
        
    def __init__(self, submittor, evaluator, project_id):
        self.submittor  = submittor
        self.evaluator  = evaluator
        self.project_id = project_id
        
        self._posts     = None
        self._file      = None
        self._issue_num = None
        self._template = None
        self._status = None
        self._scores = None
        
        
    @property
    def assign_dir(self):
        return op.join(
            course_dir(), 
            f"mp0{self.project_id}", 
            "assignments"
        )
        
    @property
    def issue_num(self):
        if self._issue_num is None:
            for fname in os.listdir(self.assign_dir):
                if match := re.match(f"{self.submittor}_issue(\d+).md", fname):
                    self._issue_num = int(match.group(1))
            
        return self._issue_num
        
    @property 
    def file(self):
        if self._file is None:
            self._file = op.join(latest_issues_dir(), f"issue{self.issue_num:03g}.json")
        return self._file
    
    @property
    def posts(self):
        if self._posts is None:
            with open(self.file, "r") as f:
                issue_contents = json.loads(f.read())
                
            self._posts = "\n".join(c["text"] for c in issue_contents["comments"] if c["commenter"] == self.evaluator)
            
        return self._posts
    
    @property 
    def status(self):
        if self._status is None:
            if not self.posts: 
                self._status = "NOT SUBMITTED"
            else: 
                if re.match(self.template, self.posts, flags=re.DOTALL):
                    self._status = "PROPERLY FORMATTED"
                else: 
                    self._status = "IMPROPERLY FORMATTED"
            
        return self._status
    
    @property
    def missing(self):
        return self.status == "NOT SUBMITTED"
    
    @property
    def improper(self):
        return self.status == "IMPROPERLY FORMATTED"
    
    @property
    def ok(self):
        return self.status == "PROPERLY FORMATTED"

# FIXME: This technically isn't sufficient for arbitrary URLs, but it
# seems to cover the whole GitHub API, which is enough for us.
URL_REGEX = "http[A-Za-z0-9:/\\.\\-]+"

SCORES_STR = ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10"]

def is_nan(x):
    if type(x) == float:
        return math.isnan(x)
    else:
        return False


def str_simplify(x):
    return re.sub("\\s+", " ", x.replace(" +", " ").lower())


def vecho(*args, **kwargs):
    if click.get_current_context().params["verbose"]:
        return click.echo(*args, **kwargs)
    return None


def print_web_to_pdf(url, output_file):
    CHROME = "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
    FLAGS = ["--headless", "--disable-gpu"]

    OUTPUT = f"--print-to-pdf={output_file}"
    INPUT = url

    return subprocess.run([CHROME] + FLAGS + [OUTPUT] + [INPUT], check=True)


def open_email(
    *,
    to="michael.weylandt@baruch.cuny.edu",
    subject=None,
    bcc=None,
    body=None,
    flag_auto=True,
):
    ## This function is _incredibly_ brittle, but it seems like,
    ## at a minimum, the "to" field is mandatory.
    URL_BASE = "https://outlook.office.com/mail/deeplink/compose"
    URL_PATH = ""

    if to:
        if not is_list_like(to):
            to = [to]
        URL_PATH += "?mailtouri=mailto:" + quote(",".join(to))

    if subject:
        if body and flag_auto:
            subject = "[AUTOGENERATED: SEE END OF EMAIL FOR CONTENT] " + subject
        URL_PATH += "?subject=" + quote(subject)

    if bcc:
        if not is_list_like(bcc):
            bcc = [bcc]
        URL_PATH += "?bcc=" + quote(",".join(bcc))

    ## Body doesn't play well with signature
    ## See https://stackoverflow.com/q/79482557
    ##
    ## For now, I'll just lump this into the subject and manually copy from there
    if body:
        URL_PATH += "?body=" + quote(body)

    webbrowser.open(URL_BASE + URL_PATH, new=1)


@cache
def git_version():
    "Return the current git hash (for use in auto-posting to student repos"
    # https://stackoverflow.com/a/57683700
    git_describe = subprocess.check_output(["git", "describe", "--always"])
    return git_describe.strip().decode()


@cache
def gh_pat():
    "Read GitHub PAT from relevant file"
    with open(".githubPAT") as f:
        return f.read().strip()


@cache
def _gh(path, get=True, data=None):
    headers = {
        "Accept": "application/vnd.github+json",
        "Authorization": f"Bearer {gh_pat()}",
        "X-GitHub-Api-Version": "2022-11-28",
    }

    fullpath = "https://api.github.com/" + path

    if get:
        return r.get(fullpath, headers=headers).json()
    else:
        return r.post(fullpath, headers=headers, data=data)


@cache
def gh_list_issues(owner=None):
    ALL_ISSUES = []
    pagination = 1
    
    while((len(ALL_ISSUES) % 100) == 0): 
        resp = _gh(f"/repos/michaelweylandt/{course_repo()}/issues?state=all&per_page=100&page={pagination}")

        if "status" in resp and resp["status"] != "200":
            raise click.ClickException("UNABLE TO ACCESS GITHUB API")
        
        ALL_ISSUES += resp
        pagination += 1

    ISSUES_DICT = {
        (i["number"], str_simplify(i["title"])): Issue(
            i["title"],
            i["number"],
            i["html_url"],
            i["body"],
            i["state"],
            i["user"]["login"],
        )
        for i in ALL_ISSUES
    }

    if owner:
        ISSUES_DICT = {
            k: v
            for k, v in ISSUES_DICT.items()
            if owner.lower() in v.title.lower() or owner.lower() in v.opened_by.lower()
        }

    return ISSUES_DICT


@cache
def gh_list_comments(issue_id):
    resp = _gh(f"/repos/michaelweylandt/{course_repo()}/issues/{issue_id}/comments")
    if "status" in resp and resp["status"] != "200":
        return list()
    return [
        Comment(c["user"]["login"], c["body"], c["created_at"], c["html_url"])
        for c in resp
    ]


def gh_issue_comment(issue_id, text):
    return _gh(
        f"/repos/michaelweylandt/{course_repo()}/issues/{issue_id}/comments",
        get=False,
        data=json.dumps({"body": text}),
    )


def gh_issue_create(title, text):
    return _gh(
        f"/repos/michaelweylandt/{course_repo()}/issues",
        get=False,
        data=json.dumps({"title": title, "body": text}),
    )


@cache
def course_dir():
    click.echo("Reading configuration from _teaching.yml")
    with open("_teaching.yml") as f:
        course_config = yaml_load(f)
        click.echo("Course Configuration: \n" + pformat(course_config))

    return op.expanduser(course_config["gradedir"])

@cache 
def latest_issues_dir():
    return op.join(course_dir(), "latest", "issues")

@cache
def load_issues():
    issues_dir = op.join(course_dir(), "latest", "issues")

    ALL_ISSUES = []
    for fname in glob(op.join(issues_dir, "*.json")):
        with open(fname) as f:
            RAW_ISSUE = json.loads(f.read())
            ISSUE = {
                "title": RAW_ISSUE["title"],
                "number": RAW_ISSUE["number"],
                "comments": [
                    (c["commenter"], c["text"]) for c in RAW_ISSUE["comments"]
                ],
            }
            ALL_ISSUES.append(ISSUE)

    ALL_ISSUES.sort(key=lambda x: x["number"])

    return ALL_ISSUES


@cache
def course_short():
    with open("_variables.yml") as f:
        course_config = yaml_load(f)

    return course_config["course"]["short"]


@cache
def course_repo():
    with open("_variables.yml") as f:
        course_config = yaml_load(f)

    return course_config["course"]["repo"]


@cache
def roster_file():
    filename = Path(op.join(course_dir(), "roster.json")).resolve(strict=True)
    filename.touch(exist_ok=True)
    return filename


@cache
def grades_file():
    filename = Path(op.join(course_dir(), "grades.json")).resolve()
    filename.touch(exist_ok=True)
    return filename


@cache
def teams_file():
    filename = Path(op.join(course_dir(), "teams.json")).resolve()
    filename.touch(exist_ok=True)
    return filename


@cache
def team_grades_file():
    filename = Path(op.join(course_dir(), "team_grades.json")).resolve()
    filename.touch(exist_ok=True)
    return filename


@cache
def mapping_file():
    filename = Path(op.join(course_dir(), "master_mapping.json"))
    filename.touch(exist_ok=True)
    return filename.resolve(strict=True)


@cache
def mapping_index_file():
    filename = Path(op.join(course_dir(), "mapping_indices.json"))
    filename.touch(exist_ok=True)
    return filename.resolve(strict=True)

def number_to_letter(score):
    if score >= 97:   # 97-100
        return "A+"
    elif score >= 93: # 94-97
        return "A"
    elif score >= 90: # 90-92
        return "A-"
    elif score >= 87: # 87-89 
        return "B+"
    elif score >= 83: # 83-86
        return "B"
    elif score >= 80: # 80-82
        return "B-"
    elif score >= 77: # 77-79
        return "C+"
    elif score >= 73: # 73-76
        return "C"
    elif score >= 70: # 70-72
        return "C-"
    elif score >= 67: # 67-69
        return "D+"
    elif score >= 63: # 63-66
        return "D"
    elif score >= 60: # 60-62
        return "D-"
    else:
        return "F"

def get_pf_mapping(project_id):
    """Load peer feedback mapping for MP#N.

    Returns a dict of with (REVIEWER_NAME, GITHUB, EMAIL) keys and a list of
    (AUTHOR, URL) pairs as the value."""
    with open(mapping_file(), "r") as f:
        MASTER_MAPPING = json.loads(f.read())

    with open(mapping_index_file(), "r") as f:
        MAPPING_INDEX = json.loads(f.read())
        MAPPING_INDEX = MAPPING_INDEX[f"mp0{project_id}"]

    ROSTER = current_roster()

    MAPPING = {}
    PF_DIR = op.join(course_dir(), f"mp0{project_id}", "assignments")

    for row in ROSTER.itertuples(index=False):
        name = row.name
        gh = row.github
        email = row.email

        key = (name, gh, email)

        value = []
        for ix in MAPPING_INDEX:
            author = MASTER_MAPPING[gh][ix]

            issue = glob(op.join(PF_DIR, f"{author}_*.md"))

            if not issue:
                click.echo(
                    f"No issue assignment found for {author} on MP #0{project_id}. Skpping."
                )
                continue

            if len(issue) > 1:
                raise click.ClickException(f"Multiple issues found for {author} on MP #0{project_id}")

            issue_file = op.basename(issue[0])
            issue_num = int(re.search("_issue([0-9]+)\\.md$", issue_file).group(1))

            if not issue_file:
                raise click.ClickException("Issue appears to be issue #0. Please confirm all PF properly assigned.")

            issue_url = (
                f"https://github.com/michaelweylandt/{course_repo()}/issues/{issue_num}"
            )
            value.append((author, issue_url))

        MAPPING[key] = value

    return MAPPING


@click.group()
@click.option(
    "-v", "--verbose", count=True, help="Include additional output", default=False
)
@click.option(
    "-q",
    "--quiet",
    is_flag=True,
    help="Suppress default output. If `verbose` is given, it takes precedence over this flag.",
)
def course_manager(verbose, quiet):
    """Course Management Tool (CISSOID) for STA9750

    This tool can be used to perform various administrative things (e.g., roster
    management, peer feedback assignment, etc.) associated with STA 9750."""

    click.echo("Results to be stored in directory: " + course_dir())


@course_manager.group()
def roster():
    """Course Roster Management

    This subcommand manages the course roster. As part of Mini-Project #00, students
    should register their GitHub ID with the instructor. The instructor must log
    these GitHub IDs here. Once the course is underway, the instructor can use
    this command to drop / deactive students, delete them entirely (in rare
    circumstances) or otherwise manage the course. Note that this roster is
    used implicitly by all other commands, so it must be kept up to date."""

def current_roster(include_inactive=False):
    try:
        ROSTER = pd.read_json(roster_file())
        
        if include_inactive:
            return ROSTER
        else: 
            return ROSTER[ROSTER["active"]]
    except: 
        return pd.DataFrame()

def current_teams():
    try:
        return pd.read_json(teams_file())
    except ValueError:
        return pd.DataFrame()


@roster.command(name="list")
@click.option(
    "-I",
    "--include-inactive",
    help="Should GitHub inactive students bee included?",
    default=False,
    is_flag=True
)
@click.option(
    "-E", 
    "--include_emplid", 
    help="Should EmplID be printed?",
    default=False,
    is_flag=True
)
def roster_list(include_inactive, include_emplid):
    """Print current course roster"""
    
    roster = current_roster(include_inactive=include_inactive)
    teams = current_teams()
    
    full_roster = pd.merge(
        roster, 
        teams.rename(columns={
            "name": "team_name", 
            "number": "team_number"
         }),
        left_on="project_team", 
        right_on="team_number", how="left").\
    drop(["project_team", "team_number"], axis=1)
    
    full_roster.index = full_roster.index + 1
    
    if not include_emplid:
        full_roster = full_roster.drop(["emplid"], axis=1)
        
    if not include_inactive:
        full_roster = full_roster.drop(["active"], axis=1)
        
    full_roster = full_roster.rename(columns={
        "github": "GitHub ID", 
        "email": "Student Email", 
        "name": "Student Name", 
        "team_name": "Project Team Name", 
        "active": "Status",
        "emplid": "Student ID"
    })
    
    click.echo(full_roster.to_markdown(index=True))
    if include_inactive:
        click.echo(f"{full_roster.shape[0]} total students registered (including inactive).")
    else: 
        click.echo(f"{full_roster.shape[0]} active students registered.")

@roster.command(name="add")
@click.option(
    "-g",
    "--github",
    help="Student's GitHub ID",
    prompt="What is the Student's GitHub ID?",
)
@click.option(
    "-e", "--email", help="Student's Email", prompt="What is the Student's Email?"
)
@click.option(
    "-E",
    "--emplid",
    help="Student's CUNY EmplID",
    prompt="What is the Student's CUNY EmplID?",
)
@click.option(
    "-n",
    "--name",
    help="Student's Real Name",
    prompt="What is the Student's Real Name?",
)
def roster_add(github, email, emplid, name):
    """Add a new student to the roster.

    This function is intended for use following MP00. As part of MP00,
    students need to register their GitHub ID and contact info with the
    instructor. This function maintains a roster which is used for all later
    course activities."""
    NEW_STUDENT = pd.DataFrame(
        {
            "github": github,
            "email": email,
            "emplid": emplid,
            "name": name,
            "active": True,
            "project_team": None,
        },
        index=[emplid],
    )

    ROSTER = current_roster()

    if not ROSTER.empty and github in ROSTER.github.values:
        warning("Student with GitHub ID", github, "already in roster.")
        click.confirm("Should I overwrite?", abort=True)

    NEW_ROSTER = pd.concat([ROSTER, NEW_STUDENT], ignore_index=True)

    click.echo("The following student has been added to the roster")
    click.echo(NEW_STUDENT)

    with open(roster_file(), "w+") as f:
        f.write(NEW_ROSTER.to_json(orient="records", indent=2))


@roster.command(name="delete")
@click.option(
    "--github",
    help="Student's GitHub ID",
    prompt="What is the Student's GitHub ID?",
    prompt_required=False,
    default=None,
)
def roster_delete(github):
    """Delete a student from the course roster.

    This function should only be used in exceptional circumstances.
    Students who drop the course are better handled by marking them
    as inactive, rather than deleting all records."""
    ROSTER = current_roster()

    click.echo(ROSTER)

    if github is None:
        github = click.prompt(
            "Which student would you like to delete?",
            type=click.Choice(ROSTER.github.values),
        )

    if github not in ROSTER.github.values:
        raise click.ClickException("Could not match user to existing roster")

    DROPPER = ROSTER.loc[ROSTER["github"] == github]

    click.echo("Student to be deleted:")
    click.echo(DROPPER)
    click.confirm("Are you sure you want to delete this student?", abort=True)

    NEW_ROSTER = ROSTER.loc[ROSTER["github"] != github]

    with open(roster_file(), "w+") as f:
        f.write(NEW_ROSTER.to_json(orient="records", indent=2))
        

@roster.command(name="edit")
@click.option(
    "-g",
    "--github",
    help="Student's GitHub ID",
    prompt="What is the Student's GitHub ID?",
    prompt_required=False,
    default=None,
)
@click.option(
    "-F",
    "--field",
    type=click.Choice(
        ["Name", "GitHub", "Email", "EmplID"], case_sensitive=False
    ),
    help="Which field to modify?",
    prompt="Which field should be modified?",
)
def roster_edit(github, field):
    """Edit a student on the course roster.

    This function is not yet implemented."""
    
    ROSTER = current_roster(include_inactive=True)
 
    if not github:
        click.echo("The current roster contains the following students:")
        for row in ROSTER.itertuples():
            click.echo(f"{row.Index:02g}. {row.name} - {row.github}")

        number = click.prompt(
            "Which student would you like to modify?",
            type=click.IntRange(min=ROSTER.index.min(), max=ROSTER.index.max()),
        )
        
        github = ROSTER.loc[number].github
        
    if github not in ROSTER.github.values:
        raise click.ClickException(f"No student with GitHub ID {github} found")
        
    roster_ix = (ROSTER.github == github).where(lambda x: x).dropna().index.values[0]

    click.echo("-------")
    click.echo("You are about to edit the following student:")
    
    click.echo(f"Name: {ROSTER.loc[roster_ix, 'name']}")
    click.echo(f"GitHub: {ROSTER.loc[roster_ix, 'github']}")
    click.echo(f"Email: {ROSTER.loc[roster_ix, 'email']}")
    click.echo(f"EmplID: {ROSTER.loc[roster_ix, 'emplid']}")
    click.echo("-------")

    field_new_value = click.prompt(
            f"Enter the new {field} for this student. (Leave blank to skip change.)",
            default=ROSTER.loc[roster_ix, field.lower()],
            show_default=True,
        )
        
    ROSTER.loc[roster_ix, field.lower()] = field_new_value
    
    click.echo("Updated Values:")
    click.echo("-------")
    click.echo(f"Name: {ROSTER.loc[roster_ix, 'name']}")
    click.echo(f"GitHub: {ROSTER.loc[roster_ix, 'github']}")
    click.echo(f"Email: {ROSTER.loc[roster_ix, 'email']}")
    click.echo(f"EmplID: {ROSTER.loc[roster_ix, 'emplid']}")
    click.echo("-------")
    
    click.confirm(
            f"Are you sure you would like to update this student as shown above?",
            abort=True,
        )
        
    with open(roster_file(), "w+") as f:
        f.write(ROSTER.to_json(orient="records", indent=2))

@roster.command(name="deactivate")
@click.option(
    "--github",
    help="Student's GitHub ID",
    prompt="What is the Student's GitHub ID?",
    prompt_required=False,
    default=None,
)
def roster_deactivate(github):
    """Deactivate a student on the course roster.

    This function is not yet implemented."""
    ROSTER = current_roster(include_inactive=True)
 
    if not github:
        click.echo("The current roster contains the following active students:")
        for row in ROSTER.itertuples():
            if row.active:
                click.echo(f"{row.Index:02g}. {row.name} - {row.github}")

        number = click.prompt(
            "Which student would you like to deactivate?",
            type=click.IntRange(min=ROSTER.index.min(), max=ROSTER.index.max()),
        )
        
        github = ROSTER.loc[number].github
        
    if github not in ROSTER.github.values:
        raise click.ClickException(f"No student with GitHub ID {github} found")
        
    roster_ix = (ROSTER.github == github).where(lambda x: x).dropna().index.values[0]
    
    if ROSTER.loc[roster_ix, 'active'] is False:
        raise click.ClickException(f"Student {github} is already inactive.")

    click.echo("-------")
    click.echo("You are about to deactivate the following student:")
    
    click.echo(f"Name: {ROSTER.loc[roster_ix, 'name']}")
    click.echo(f"GitHub: {ROSTER.loc[roster_ix, 'github']}")
    click.echo(f"Email: {ROSTER.loc[roster_ix, 'email']}")
    click.echo(f"EmplID: {ROSTER.loc[roster_ix, 'emplid']}")
    click.echo("-------")

    ROSTER.loc[roster_ix, "active"] = False
    
    click.confirm(
            f"Are you sure you would like to deactivate this student?",
            abort=True,
        )
        
    with open(roster_file(), "w+") as f:
        f.write(ROSTER.to_json(orient="records", indent=2))


@roster.command(name="reactivate")
@click.option(
    "--github",
    help="Student's GitHub ID",
    prompt="What is the Student's GitHub ID?",
    prompt_required=False,
    default=None,
)
def roster_reactivate(github):
    """Reactivate a student on the course roster.

    This function is not yet implemented."""
    ROSTER = current_roster(include_inactive=True)
 
    if not github:
        click.echo("The current roster contains the following inactive students:")
        for row in ROSTER.itertuples():
            if not row.active:
                click.echo(f"{row.Index:02g}. {row.name} - {row.github}")

        number = click.prompt(
            "Which student would you like to reactivate?",
            type=click.IntRange(min=ROSTER.index.min(), max=ROSTER.index.max()),
        )
        
        github = ROSTER.loc[number].github
        
    if github not in ROSTER.github.values:
        raise click.ClickException(f"No student with GitHub ID {github} found")
        
    roster_ix = (ROSTER.github == github).where(lambda x: x).dropna().index.values[0]
    
    if ROSTER.loc[roster_ix, 'active'] is True:
        raise click.ClickException(f"Student {github} is already active.")

    click.echo("-------")
    click.echo("You are about to reactivate the following student:")
    
    click.echo(f"Name: {ROSTER.loc[roster_ix, 'name']}")
    click.echo(f"GitHub: {ROSTER.loc[roster_ix, 'github']}")
    click.echo(f"Email: {ROSTER.loc[roster_ix, 'email']}")
    click.echo(f"EmplID: {ROSTER.loc[roster_ix, 'emplid']}")
    click.echo("-------")

    ROSTER.loc[roster_ix, "active"] = True
    
    click.confirm(
            f"Are you sure you would like to reactivate this student?",
            abort=True,
        )
        
    with open(roster_file(), "w+") as f:
        f.write(ROSTER.to_json(orient="records", indent=2))

@course_manager.group()
def project():
    """Course Project Management

    This subcommand manages the course project. It includes functionality to create
    groups, add students to them, and to assign grades for group-based work."""

@project.command(name="create")
def project_create():
    "Define a new team. After running this, use 'modify' to add or remove students."

    TEAMS = current_teams()
    n_teams, _ = TEAMS.shape

    new_team_number = n_teams + 1
    NEW_TEAM = pd.DataFrame(
        {
            "number": new_team_number,
            "name": "TBD",
        },
        index=[new_team_number],
    )

    NEW_TEAMS = pd.concat([TEAMS, NEW_TEAM], ignore_index=True)

    click.echo("The following team has been added to the roster")
    click.echo(NEW_TEAM)

    ROSTER = current_roster(include_inactive=True)
    
    n_roster = ROSTER.shape[0]

    while True:
        click.echo("The following students have not yet been assigned a team:")
        NO_TEAM = ROSTER[ROSTER["project_team"].isna()]["name"].to_dict()

        for k, v in NO_TEAM.items():
            if ROSTER[ROSTER.name == v].active.item():
                click.echo(f"- {k}: {v}")

        id_to_add = click.prompt(
            "Enter the number of a student to add to this team. (Leave blank to finish team creation.)",
            default="",
            show_default=False,
        )

        if not id_to_add:
            click.echo("Team creation complete.")
            break

        try:
            id_to_add = int(id_to_add)
        except ValueError:
            click.echo("I was expecting an integer or a blank. Please try again.")
            continue

        if id_to_add not in NO_TEAM:
            click.echo("I don't recognize that key. Please try again.")
            continue

        ROSTER.at[id_to_add, "project_team"] = new_team_number

    click.echo("The following team has been added to the roster")
    click.echo(NEW_TEAM)
    click.echo("The team members are:")
    for nm in ROSTER[ROSTER["project_team"] == new_team_number]["name"]:
        click.echo(f"- {nm}")

    click.confirm("Should I create this team?", abort=True)
    
    if ROSTER.shape[0] != n_roster:
        click.echo("Roster has changed length!!")
        import pdb; pdb.set_trace()

    with open(teams_file(), "w+") as f:
        f.write(NEW_TEAMS.to_json(orient="records", indent=2))

    with open(roster_file(), "w+") as f:
        f.write(ROSTER.to_json(orient="records", indent=2))


@project.command(name="edit")
@click.option("-N", "--number", default=0, help="Number of team to modify")
@click.option(
    "-A",
    "--action",
    type=click.Choice(
        ["Rename", "Add-Student", "Remove-Student"], case_sensitive=False
    ),
    help="Which action to take?",
    prompt="Which modification should be performed?",
)
def project_edit(number, action):
    "Add or remove students from a team or change team name"

    TEAMS = current_teams()
    N_TEAMS, _ = TEAMS.shape

    if number > N_TEAMS or number < 0:
        raise click.ClickException("Invalid team number provided.")

    if number == 0:
        click.echo("The current teams are:")
        for ix, row in enumerate(TEAMS.itertuples(), start=1):
            click.echo(f"{ix:02g}. Team Number {row.number} - {row.name}")

        number = click.prompt(
            "Which team would you like to modify?",
            type=click.IntRange(min=TEAMS["number"].min(), max=TEAMS["number"].max()),
        )

    ROSTER = current_roster()
    n_roster = ROSTER.shape[0]
    
    BIG_ROSTER = pd.merge(
        ROSTER,
        TEAMS.rename(columns={"name": "team_name"}),
        how="left",
        left_on="project_team",
        right_on="number",
    )

    TEAM = BIG_ROSTER[BIG_ROSTER["project_team"] == number]

    click.echo("You are about to assign modify the team consisting of:")
    click.echo("--------")
    for ix, row in enumerate(TEAM.itertuples(), start=1):
        click.echo(f"{ix:02g}. {row.name} (GH: {row.github}; EMAIL: {row.email})")
    click.echo("--------")

    if action == "Remove-Student":
        click.echo("These students are presently on that team:")
        click.echo("------")
        for ix in TEAM.index:
            student = TEAM.loc[ix]
            
            if student["active"]:
                click.echo(f"- {ix}: {student['name']}")
        click.echo("------")
        
        id_to_drop = click.prompt(
            "Enter the number of the student to drop from this team.",
            show_default=False,
            type=click.Choice([str(k) for k in TEAM.index])
        )

        try:
            id_to_drop = int(id_to_drop)
        except ValueError:
            raise click.ClickException("I was expecting an integer.")
        
        ROSTER.at[id_to_drop, "project_team"] = math.nan
        
        click.echo("The new roster of this team is:")
        for nm in ROSTER[ROSTER["project_team"] == number]["name"]:
            click.echo(f"- {nm}")
            
        click.echo("------")
        click.echo("The following students have no team:")
        for nm in ROSTER[ROSTER["project_team"].isna()]["name"]:
            click.echo(f"- {nm}")

        click.confirm("Should I make this change?", abort=True)
    
        if ROSTER.shape[0] != n_roster:
            click.echo("Roster has changed length!!")
            import pdb; pdb.set_trace()

        with open(roster_file(), "w+") as f:
            f.write(ROSTER.to_json(orient="records", indent=2))


    elif action == "Add-Student":
        NO_TEAM = ROSTER[ROSTER["project_team"].isna()]["name"].to_dict()

        click.echo("These students are not presently on a team:")
        click.echo("--------")
        
        for k, v in NO_TEAM.items():
            if ROSTER[ROSTER.name == v].active.item():
                click.echo(f"- {k}: {v}")
                
        click.echo("--------")

        id_to_add = click.prompt(
            "Enter the number of a student to add to this team.",
            show_default=False,
            type=click.Choice([str(k) for k in NO_TEAM.keys()])
        )

        try:
            id_to_add = int(id_to_add)
        except ValueError:
            raise click.ClickException("I was expecting an integer.")

        ROSTER.at[id_to_add, "project_team"] = number
        
        click.echo("The new roster of this team is:")
        for nm in ROSTER[ROSTER["project_team"] == number]["name"]:
            click.echo(f"- {nm}")

        click.confirm("Should I create this team?", abort=True)
    
        if ROSTER.shape[0] != n_roster:
            click.echo("Roster has changed length!!")
            import pdb; pdb.set_trace()

        with open(roster_file(), "w+") as f:
            f.write(ROSTER.to_json(orient="records", indent=2))

    elif action == "Rename":
        current_name = TEAM["team_name"].iloc[0]
        click.echo(f"The current name of this team is {current_name}.")
        new_name = click.prompt("What should the new name of this team be?")

        if new_name in TEAMS["name"]:
            click.echo("WARNING: This team name is already in use. Be careful.")

        click.confirm(
            f"Are you sure you would like to change the name of Team {number} from {current_name} to {new_name}?",
            abort=True,
        )

        TEAMS.loc[TEAMS["number"] == number, "name"] = new_name

        with open(teams_file(), "w+") as f:
            f.write(TEAMS.to_json(orient="records", indent=2))


@project.command(name="list")
def project_list():
    "List existing teams (with members) and identify students not yet on a team."
    ROSTER = current_roster()
    TEAMS = current_teams()
    BIG_ROSTER = pd.merge(
        ROSTER,
        TEAMS.rename(columns={"name": "team_name"}),
        how="left",
        left_on="project_team",
        right_on="number",
    )
    
    n_teams = (BIG_ROSTER["number"].notna()).sum()
    
    click.echo(f"{n_teams} of {ROSTER.shape[0]} students are on a project team.")
    click.echo(f"{TEAMS.shape[0]} total teams have been registered.")
    click.echo("--------------")
    
    TEAM_NUMS = BIG_ROSTER["project_team"].unique()
    TEAM_NUMS.sort()

    for team_num in TEAM_NUMS:
        if pd.isna(team_num):
            continue

        team_name = TEAMS[TEAMS["number"] == team_num]["name"].item()

        SUB_ROSTER = BIG_ROSTER[BIG_ROSTER["number"] == team_num]
        

        click.echo(
            f"Team Number {int(team_num)} (current name {team_name}) has the following {SUB_ROSTER.shape[0]} members:"
        )

        for ix, nm in enumerate(SUB_ROSTER["name"], start=1):
            click.echo(f"- {ix:02g}. {nm}")
        click.echo("--------------")

    SUB_ROSTER = BIG_ROSTER[BIG_ROSTER["project_team"].isna()]

    if SUB_ROSTER.shape[0]:
        click.echo(f"The following {SUB_ROSTER.shape[0]} students have not yet been assigned a team:")
    
        for ix, nm in enumerate(SUB_ROSTER["name"], start=1):
            click.echo(f"- {ix:02g}. {nm}")


@project.command(name="grade")
@click.option(
    "--element",
    type=click.Choice(["Proposal", "Check-In", "Final", "Summary-Report"], case_sensitive=False),
    help="Which project element to assign grades for?",
    prompt="Which project element should grades be assigned for?",
)
@click.option("-N", "--number", default=0, help="Number of team to grade")
@click.option(
    "--skip-email",
    default=False,
    is_flag=True,
    help="Should email feedback be skipped?",
)
def project_grade(element, number, skip_email):
    "Assign group project grades"

    TEAMS = current_teams()
    N_TEAMS, _ = TEAMS.shape

    if number > N_TEAMS or number < 0:
        raise click.ClickException("Invalid team number provided.")

    if number == 0:
        click.echo("The current teams are:")
        for row in TEAMS.itertuples():
            click.echo(f"Team Number {row.number} - {row.name}")

        number = click.prompt(
            "Which team would you like to provide feedback to?",
            type=click.IntRange(min=TEAMS["number"].min(), max=TEAMS["number"].max()),
        )

    ROSTER = current_roster()
    BIG_ROSTER = pd.merge(
        ROSTER,
        TEAMS.rename(columns={"name": "team_name"}),
        how="left",
        left_on="project_team",
        right_on="number",
    )

    TEAM = BIG_ROSTER[BIG_ROSTER["project_team"] == number]
    TEAM_NAME = TEAM["team_name"].iloc[0]

    click.echo("You are about to assign feedback to the team consisting of:")
    for row in TEAM.itertuples():
        click.echo(
            f"{row.name} (GH: {row.github}; EMAIL: {row.email}) - {row.team_name}"
        )

    feedback_dir = op.join(course_dir(), element.lower())
    os.makedirs(feedback_dir, exist_ok=True)

    feedback_file = op.join(feedback_dir, f"team_{number}.txt")

    if op.exists(feedback_file):
        new_feedback = click.confirm(
            f"Feedback already found for Team {number}. Are you sure you want to overwrite?"
        )
    else:
        new_feedback = True

    if new_feedback:
        TEMPLATES = Environment(
            loader=FileSystemLoader("_cissoid/templates"),
            autoescape=select_autoescape(),
        )

        TEMPLATE = TEMPLATES.get_template(f"project_{element.lower()}.md")
        
        if element == "Summary-Report":
            report_url = click.prompt("What URL was used for the graded report?")
        else: 
            report_url = None

        SKELETON = TEMPLATE.render(team_name=TEAM_NAME, 
                                   members=TEAM.itertuples(), 
                                   report_url=report_url)

        FEEDBACK = click.edit(text=SKELETON, editor="/usr/bin/nano")

        with open(feedback_file, "w") as f:
            f.write(FEEDBACK)

    with open(feedback_file, "r") as f:
        FEEDBACK_TXT = f.read()

    scores = [int(s) for s in re.findall("points\\): (\\d{,2})", FEEDBACK_TXT)]
    total = sum(scores)

    with open(team_grades_file(), "r") as f:
        file_text = f.read()

        if not file_text:
            ALL_GRADES = dict()
        else:
            ALL_GRADES = json.loads(file_text)

    if element.lower() not in ALL_GRADES:
        ALL_GRADES[element.lower()] = dict()

    ALL_GRADES[element.lower()][number] = total

    with open(team_grades_file(), "w") as f:
        f.write(json.dumps(ALL_GRADES, indent=2))

    if skip_email:
        return 0

    open_email(
        subject=f"STA 9750 - Team {TEAM_NAME} - Project {element} - Score {total}",
        to=TEAM["email"].to_list(),
        body=FEEDBACK_TXT,
    )


@project.command(name="report")
@click.option(
    "-g",
    "--github",
    multiple=True,
    help="GitHub ID to archive. Can be given multiple times. If blank, all active students in roster.",
)
def project_report(github):
    "Assign grades to individual final reports"
    
    ROSTER = current_roster()
    
    if not github:
        process_all = True
        github = ROSTER.github.to_list()
    else: 
        process_all = False
        
    feedback_dir = op.join(course_dir(), "final_report_grades")
    os.makedirs(feedback_dir, exist_ok=True)
    
    template = Environment(loader=FileSystemLoader("_cissoid/templates"), autoescape=select_autoescape()).get_template("project_final_report.md")
    
    random.shuffle(github)

    for g in github: 
        feedback_file = op.join(feedback_dir, f"final_report_{g}.txt")

        if op.exists(feedback_file):
            if process_all: 
                continue # Just assume we're skipping if name not explicitly asked for
            
            if not click.confirm(f"Final report feedback already found for {g}. Are you sure you want to overwrite?"):
                continue
        
        report_url = click.prompt(f"What URL was used for {g}'s final report?", default='Not Submitted')
        
        if report_url == 'Not Submitted': 
            continue
        
        if click.confirm("Would you like me to open the report now?", default=True):
            webbrowser.open(report_url)
        
        try: 
            resp = r.get(report_url)
            bs = BS(resp.text, features="lxml")
            word_count = sum([len(p.text.split()) for p in bs.find("main").findAll("p")])
        except: 
            import pdb; pdb.set_trace()
            
        full_name = ROSTER[ROSTER.github == g].name.item()
    
        code_quality = click.prompt("What grade should be assigned for Code Quality?", 
                                    type=click.IntRange(min=0, max=100))
                                    
        code_quality_txt = click.prompt("Any particular feedback on Code Quality?", type=str, default=None)
        code_quality_txt = f"({number_to_letter(code_quality)}) {code_quality_txt}"
        
        data_acquisition = click.prompt("What grade should be assigned for Data Acquisition and Processing?", 
                                    type=click.IntRange(min=0, max=100))
                                    
        data_acquisition_txt = click.prompt("Any particular feedback on Data Acquisition and Processing?", type=str, default=None)
        data_acquisition_txt = f"({number_to_letter(data_acquisition)}) {data_acquisition_txt}"
        
        data_analysis = click.prompt("What grade should be assigned for Data Analysis?", 
                                    type=click.IntRange(min=0, max=100))
                                    
        data_analysis_txt = click.prompt("Any particular feedback on Data Analysis?", type=str, default=None)
        data_analysis_txt = f"({number_to_letter(data_analysis)}) {data_analysis_txt}"
        
        communication = click.prompt("What grade should be assigned for Communication and Presentation of Results?", 
                                    type=click.IntRange(min=0, max=100))
                                    
        communication_txt = click.prompt("Any particular feedback on Communication and Presentation of Results?", type=str, default=None)
        communication_txt = f"({number_to_letter(communication)}) {communication_txt}"
        
        overall_grade = round(0.2 * code_quality + 0.2 * data_acquisition + 0.3 * data_analysis + 0.3 * communication, 2)
                                    
        click.echo(f"{g} currently has an overall grade of {overall_grade}.")
        other = click.prompt("Should any other adjustments be applied?", 
                             type=click.IntRange(min=-100, max=100), 
                             default=0)
                             
        if other: 
            other_reason = click.prompt(f"Why is this adjustment ({other}) being applied?")
            overall_grade += other
        else: 
            other_reason = None
            
        skeleton = template.render(
            github_id = g, 
            full_name = full_name, 
            overall_grade = overall_grade,
            report_url = report_url,
            other = other, 
            other_reason = other_reason, 
            code_quality = code_quality, 
            data_acquisition = data_acquisition, 
            data_analysis = data_analysis, 
            code_quality_txt = code_quality_txt, 
            data_acquisition_txt = data_acquisition_txt, 
            data_analysis_txt = data_analysis_txt, 
            communication = communication, 
            communication_txt = communication_txt, 
            word_count = word_count
        )

        final_text = click.edit(text=skeleton, editor="/usr/bin/nano")
        
        with open(feedback_file, "w") as f:
            f.write(final_text)

    click.echo("All individual reports graded. You are now ready to return feedback to students.")
        
@course_manager.group()
def mini():
    """Mini-Project Management

    This subcommand manages the mini-projects (homework). It includes functionality
    to automatically verify GitHub submissions, to download GitHub submissions,
    to assign peer feedback, to download peer feedback once complete, and to assign
    meta-reviews."""


@mini.command(name="archive")
@click.option(
    "-N",
    "--number",
    "project_id",
    prompt="Which mini-project to archive?",
    type=click.IntRange(min=0, max=4),
)
@click.option(
    "-g",
    "--github",
    multiple=True,
    help="GitHub ID to archive. Can be given multiple times. If blank, all active students in roster.",
)
@click.option("--skip-pdf", is_flag=True, default=False, help="Skip PDF archiving")
def mini_archive(project_id, github, skip_pdf):
    """Archive Student Mini-Project Submissions

    This function will archive all elements of a student's mini-project
    submission. It is designed to be used after deadlines pass, but it can
    be run repeatedly if needed. Specifically, this function will:

    1) Sync the student's Git repository (cloning if needed)
    2) Download all issue comment threads
    3) Export a PDF of their rendered site.

    PDF export depends on a headless use of Chrome/Chromium and
    may be a bit tricky to get working."""
    return _mini_archive(project_id, github, skip_pdf)


def _mini_archive(project_id, github, skip_pdf=False, 
                  archive_submissions=True, archive_issues=True):
    "Actual implementation of mini_archive. Can be called directly"
    if not github:
        github = current_roster().github.values

    latest_dir = op.join(course_dir(), "latest")
    os.makedirs(latest_dir, exist_ok=True)
    now = datetime.now().astimezone().strftime("%Y-%m-%dT%H:%M:%S_%Z")
    
    if archive_submissions:

        for gh in github:
            click.echo(f"Archiving Mini-Project #0{project_id} for User {gh}")
    
            click.echo("Syncronizing Git Repository")
    
            student_dir = op.join(course_dir(), "students", gh)
            student_git_dir = op.join(student_dir, "git")
            # Don't worry too much about race conditions / file system issues
            os.makedirs(student_git_dir, exist_ok=True)
    
            if op.exists(op.join(student_git_dir, ".git")):
                subprocess.run(["git", "-C", student_git_dir, "pull"])
            else:
                student_repo_url = f"https://github.com/{gh}/{course_repo()}"
                subprocess.run(["git", "clone", student_repo_url, student_git_dir])
    
            if skip_pdf:
                continue
    
            click.echo("Exporting Web Page as PDF")
    
            student_web_dir = op.join(student_dir, "pdfs", now)
            # Don't worry too much about race conditions / file system issues
            os.makedirs(student_web_dir, exist_ok=True)
            if project_id > 0:
                student_mp_url = f"https://{gh}.github.io/{course_repo()}/mp0{project_id}"
                student_mp_pdf = op.join(student_web_dir, f"mp0{project_id}.pdf")
            else:
                student_mp_url = f"https://{gh}.github.io/{course_repo()}/"
                student_mp_pdf = op.join(student_web_dir, "index.pdf")
    
            rr = print_web_to_pdf(student_mp_url, student_mp_pdf)
    
            if rr.returncode:
                click.echo(f"Failed to export {student_mp_url} to PDF.")
    
            latest_pdf_dir = op.join(latest_dir, "pdfs")
            os.makedirs(latest_pdf_dir, exist_ok=True)
    
            pdf_symlink = op.join(latest_pdf_dir, f"{gh}_mp{project_id}.pdf")
            try:
                os.remove(pdf_symlink)
            except FileNotFoundError:
                pass
            os.symlink(student_mp_pdf, pdf_symlink, target_is_directory=True)

    if archive_issues:
        # Now export all comments from my course issues repository
        issues_dir = op.join(course_dir(), "issues", now)
        # Don't worry too much about race conditions / file system issues
        os.makedirs(issues_dir, exist_ok=True)
    
        click.echo(f"Exporting GitHub Issues to {issues_dir}")
    
        ISSUES = [issue._asdict() for issue in gh_list_issues().values()]
    
        for issue in ISSUES:
            click.echo(f" - Exporting Issue #{issue['number']:03g}")
            issue["comments"] = [c._asdict() for c in gh_list_comments(issue["number"])]
            issue_file = op.join(issues_dir, f"issue{issue['number']:03}.json")
    
            with open(issue_file, "w") as f:
                f.write(json.dumps(issue, indent=4))
    
        issue_symlink = op.join(latest_dir, "issues")
        try:
            os.remove(issue_symlink)
        except FileNotFoundError:
            pass
        os.symlink(issues_dir, issue_symlink, target_is_directory=True)


@mini.command(name="verify")
@click.option(
    "-N",
    "--number",
    "project_id",
    prompt="Mini-Project submission to verify",
    type=click.IntRange(min=0, max=4),
)
@click.option(
    "-g",
    "--github",
    multiple=True,
    help="GitHub ID to verify. Can be given multiple times. If blank, all active students in roster. ",
)
def mini_verify(project_id, github):
    """Verify that a mini-project was submitted and formatted correctly

    This script can be used to verify correct submission of mini-projects and,
    if necessary, to highlight possible issues. This function does _not_ provide
    feedback for students and is primarily intended for instructor use.

    To process submissions after the deadline passes, use the `process` command
    instead."""
    return _mini_verify(project_id, github)


def _get_submission_urls(project_id, github, check_master=True):
    MP_URL = f"https://michael-weylandt.com/STA9750/miniprojects/mini0{project_id}.html"

    MP_PAGE = r.get(MP_URL)
    MP_TEXT = (
        BS(MP_PAGE.text, features="lxml").find(id="submission-text").get_text().strip()
    )
    BODY = MP_TEXT.replace("<GITHUB_ID>", github)
    EXPECTED_URL = re.search(URL_REGEX, BODY).group()

    if project_id:
        RAW_URL = f"https://raw.githubusercontent.com/{github}/{course_repo()}/refs/heads/main/mp0{project_id}.qmd"
    else:
        RAW_URL = f"https://raw.githubusercontent.com/{github}/{course_repo()}/refs/heads/main/index.qmd"

    if check_master and not r.get(RAW_URL).ok:
        RAW_URL_MASTER = RAW_URL.replace("main", "master")
        if r.get(RAW_URL_MASTER).ok:
            return (EXPECTED_URL, RAW_URL_MASTER)

    return (EXPECTED_URL, RAW_URL)


def _mini_verify(project_id, github):
    "Implementation of mini_verify. Can be called directly by other functions"
    MP_URL = f"https://michael-weylandt.com/STA9750/miniprojects/mini0{project_id}.html"

    MP_PAGE = r.get(MP_URL)
    MP_TEXT = (
        BS(MP_PAGE.text, features="lxml").find(id="submission-text").get_text().strip()
    )

    if not github:
        github = current_roster().github.values

    RESULTS = {g: None for g in github}

    for gh in github:
        click.echo("-----------------------------------")
        click.echo(f"Attempting to verify for user {gh}")
        TITLE = f"{course_short()} {gh} MiniProject #0{project_id}"
        BODY = MP_TEXT.replace("<GITHUB_ID>", gh)

        ISSUES = gh_list_issues(gh)

        if not ISSUES:
            click.echo(f"No issues found for user {gh} in repo {course_repo()}")
            RESULTS[gh] = (False, gh, "NO ISSUES FOUND", None)
            continue
        
        ISSUE_TITLES = [str_simplify(_.title) for _ in ISSUES.values()]

        if str_simplify(TITLE) not in ISSUE_TITLES:
            click.echo("I could not find an issue with the desired title:")
            click.echo(f" - {TITLE}")
            click.echo("I found issues with the following titles instead:")

            for t in ISSUES.values():
                click.echo(f" - {t.title} (Issue #{t.number:02g})")

            RESULTS[gh] = (False, gh, "NO TITLE MATCH", None)
            continue
        
        POTENTIAL_ISSUES = [v for v in ISSUES.values() if str_simplify(v.title) == str_simplify(TITLE)]

        if len(POTENTIAL_ISSUES) != 1: 
            import pdb; pdb.set_trace()

        ISSUE = POTENTIAL_ISSUES[0]

        if ISSUE.state != "open":
            click.echo(f"Issue {TITLE} is not in 'open' state")
            RESULTS[gh] = (False, gh, "ISSUE CLOSED", ISSUE.number)

        SUB_URL = re.search(URL_REGEX, ISSUE.body, re.IGNORECASE)
        EXPECTED_URL = re.search(URL_REGEX, BODY, re.IGNORECASE)

        if EXPECTED_URL is None:
            raise click.ClickException("Could not find expected URL in MP Instructions")

        if SUB_URL is None:
            click.echo("No URL found in submission")
            RESULTS[gh] = (False, gh, "NO URL", ISSUE.number)
            continue

        SUB_URL = SUB_URL.group()
        EXPECTED_URL = EXPECTED_URL.group()

        if SUB_URL.lower() != EXPECTED_URL.lower():
            click.echo("Submitted URL does not match MP Instructions")
            click.echo("Expected: " + EXPECTED_URL)
            click.echo("Submitted: " + SUB_URL)

            RESULTS[gh] = (False, gh, "INCORRECT URL", ISSUE.number)
            continue

        SUB_RESP = r.get(SUB_URL)

        if not SUB_RESP.ok:
            click.echo("Submitted URL did not resolve properly")
            click.echo(" - Submitted: " + SUB_URL)

            RESULTS[gh] = (False, gh, "INVALID URL", ISSUE.number)
            continue

        if project_id:
            RAW_URL = f"https://raw.githubusercontent.com/{gh}/{course_repo()}/refs/heads/main/mp0{project_id}.qmd"
        else:
            RAW_URL = f"https://raw.githubusercontent.com/{gh}/{course_repo()}/refs/heads/main/index.qmd"

        RAW_RESP = r.get(RAW_URL)

        if not RAW_RESP.ok:
            # Some students use 'master' instead of 'main' branch
            # so try this as well
            RAW_URL_MASTER = RAW_URL.replace("main", "master")
            RAW_RESP = r.get(RAW_URL_MASTER)

        if not RAW_RESP.ok:
            click.echo("Could not identify qmd source")
            click.echo(" - Not Found at Expected: " + RAW_URL)
            click.echo(" - Not Found at Alternate: " + RAW_URL_MASTER)

            RESULTS[gh] = (False, gh, "NO SOURCE", ISSUE.number)
            continue

        RESULTS[gh] = (True, gh, "SUCCESS", ISSUE.number)

    DF = pd.DataFrame(RESULTS).T
    DF.columns = ["ok", "github", "message", "issue_num"]

    click.echo("-----------------------------------")
    click.echo("----------ANALYSIS COMPLETE--------")

    github_ok = sorted(DF[DF.ok].github.values, key=str.casefold)
    n_ok = len(github_ok)

    if DF.ok.any():
        click.echo("-----------------------------------")
        click.echo(f"MP #{project_id:02g} successfully verified for {n_ok} students: ")
        for ix, g in enumerate(github_ok, start=1):
            click.echo(f"- {ix:02g} {g}")

    if not DF.ok.all():
        click.echo("-----------------------------------")
        
        DF_BAD = DF[DF.ok != True]
        DF_BAD = DF_BAD.sort_values("github", key=lambda col: col.str.lower())
        click.echo(f"Problems were identified for the following {DF_BAD.shape[0]} users:")

        for ix, row in enumerate(DF_BAD.itertuples(), start=n_ok+1):
            if row.issue_num:
                click.echo(
                    f"- {ix:02g} GitHub user {row.github} failed with message {row.message}. See https://github.com/michaelweylandt/{course_repo()}/issues/{row.issue_num} for details"
                )
            else:
                click.echo(
                    f"- {ix:02g} GitHub user {row.github} failed with message {row.message}. No suitable issue found. See above for details."
                )

    return DF


@mini.group(name="peer")
def peer():
    """Assign, collect, and evaluate peer feedback

    These functions can be used to administer the peer feedback cycle for each
    mini-project. Roughly,

    - Assign: Review all submission issues"""


def _peer_assignment_master():
    """Take all registered students and create a balanced Latin Square

    This function implements a _Balanced Latin Square_ using the algorithm
    of J.V. Bradley JASA 53, pp.525-528(1958). The code is modified from
    https://medium.com/@graycoding/balanced-latin-squares-in-python-2c3aa6ec95b9.
    Once this Latin Square is created, it can be used to create peer assignments
    for the mini-projects."""

    MAPPING_FILE = mapping_file()

    if (not op.exists(MAPPING_FILE)) or (op.getsize(MAPPING_FILE) == 0):
        NAMES = current_roster(include_inactive=True)["github"]
        
        random.shuffle(NAMES)
        n = len(NAMES)

        l = [
            [((j // 2 + 1 if j % 2 else n - j // 2) + i) % n + 1 for j in range(n)]
            for i in range(n)
        ]
        if n % 2:  # Repeat reversed for odd n
            l += [seq[::-1] for seq in l]
        MAPPING_MATRIX = np.asarray(l[:n]) - 1

        MAPPING = {}

        for ix, nm in enumerate(NAMES):
            MAPPING[nm] = NAMES[MAPPING_MATRIX[ix, 1:]].to_list()

        with open(MAPPING_FILE, "w") as f:
            f.write(json.dumps(MAPPING, indent=4))

    with open(MAPPING_FILE, "r") as f:
        MAPPING = json.loads(f.read())

    return MAPPING


def _peer_assignment_mapping(project_id, n_peers=None):
    MASTER_MAPPING = _peer_assignment_master()
    project_id_s = f"mp0{project_id}"
    
    # Check for previous mappings
    INDEX_TO_PF_FILE = op.join(course_dir(), "mapping_indices.json")

    if (not op.exists(INDEX_TO_PF_FILE)) or (op.getsize(INDEX_TO_PF_FILE) == 0):
        Path(INDEX_TO_PF_FILE).touch(exist_ok=True)

    with open(INDEX_TO_PF_FILE, "r") as f:
        try:
            INDEX_DICT = json.loads(f.read())

        except json.JSONDecodeError:
            INDEX_DICT = {}

    if project_id_s not in INDEX_DICT:
        if not n_peers:
            raise click.ClickException("Invalid team number provided.")
        
        ALL_PREVIOUS = [ix for mp in INDEX_DICT.values() for ix in mp]
        ALL_POSSIBLE = range(len(MASTER_MAPPING))
        AVAILABLE = set(ALL_POSSIBLE) - set(ALL_PREVIOUS)

        NEW_IX = [AVAILABLE.pop() for _ in range(n_peers)]
        INDEX_DICT[project_id_s] = NEW_IX

        with open(INDEX_TO_PF_FILE, "w") as f:
            f.write(json.dumps(INDEX_DICT, indent=2))

    with open(INDEX_TO_PF_FILE, "r") as f:
        INDEX_DICT = json.loads(f.read())

    INDEX_SET = INDEX_DICT[project_id_s]

    PROJECT_MAPPING = {}

    for nm, pf in MASTER_MAPPING.items():
        PROJECT_MAPPING[nm] = [pf[n] for n in INDEX_SET]

    return PROJECT_MAPPING


@peer.command(name="assign")
@click.option(
    "-N",
    "--number",
    "project_id",
    prompt="Which mini-project to archive?",
    type=click.IntRange(min=0, max=4),
)
@click.option(
    "--dry-run", "dry_run", help="Skip posting to GitHub", default=False, is_flag=True
)
@click.option(
    "--skip-archive",
    "skip_archive",
    help="Skip archiving student submissions",
    default=False,
    is_flag=True,
)
@click.option(
    "-P",
    "--peer-count",
    help="How many peers to assign per submission",
    prompt="How many peers should be assigned for each submission?",
    type=click.IntRange(min=1, max=5),
)
@click.option(
    "-s",
    "--github-skip",
    multiple=True,
    help="GitHub ID to skip submission. This is used when students have a pre-approved extension.",
)
def peer_assign(project_id, peer_count, dry_run, skip_archive, github_skip):
    """Assign Mini-Project Peer Feedback

    This command does several things:

    0) It archives all submissions for that MP
    1) It creates a mapping from submitters to peer reviewers
    2) It automatically creates assignment comments for each student,
       noting any automatically identified issues
    3) It posts comments to GitHub.

    Note that this command should only be used once per assignment.
    """
    if not skip_archive:
        _mini_archive(project_id, [])

    # We begin by loading the peer feedback
    # mapping for this assignment
    ROSTER = current_roster(include_inactive=False)
    PF_MAPPING = _peer_assignment_mapping(project_id, peer_count)

    PF_DIR = op.join(course_dir(), f"mp0{project_id}")
    os.makedirs(PF_DIR, exist_ok=True)
    os.makedirs(op.join(PF_DIR, "assignments"), exist_ok=True)

    PF_TEMPLATES = Environment(
        loader=FileSystemLoader("_cissoid/templates"), autoescape=select_autoescape()
    )

    STUDENTS = set(ROSTER.github.values)
    STUDENTS -= set(github_skip)

    for gh in STUDENTS:
        post_glob = glob(op.join(PF_DIR, "assignments", f"{gh}_issue*.md"))

        if post_glob:
            continue

        EVALUATORS = [e for e in set(PF_MAPPING[gh]) & set(ROSTER.github.values)]
        
        ISSUE_STATUS = _mini_verify(project_id, [gh])

        SUB_URL, RAW_URL = _get_submission_urls(project_id, gh)

        if ISSUE_STATUS.ok.item():
            gh_issue_num = ISSUE_STATUS.issue_num.item()
            template = PF_TEMPLATES.get_template("success.md")
        elif ISSUE_STATUS.issue_num.item():
            gh_issue_num = ISSUE_STATUS.issue_num.item()
            template = PF_TEMPLATES.get_template("fail_issue_ok.md")
        else:
            try:
                ALL_ISSUES = gh_list_issues(gh)
            except TypeError:
                import pdb; pdb.set_trace()

            ALL_ISSUES = list(ALL_ISSUES.values())
            ALL_ISSUES.sort(key=lambda i: i.number)

            if ALL_ISSUES:
                click.echo(
                    f"The following GitHub issues opened by {gh} were found on the repository."
                )
                for issue in ALL_ISSUES:
                    if issue.opened_by == gh:
                        click.echo(
                            f" - Issue Number {issue.number}. Title '{issue.title}"
                        )
                click.echo("Where would you like to assign peer feedback?")

                gh_issue_num = input(
                    "Enter the number of the issue above or 0 for opening a new issue: >> "
                )
                gh_issue_num = int(gh_issue_num)
            else:
                click.echo("No issues found. Creating new issue")
                gh_issue_num = 0

            if gh_issue_num:
                template = PF_TEMPLATES.get_template("fail_issue_selected.md")
            else:
                template = PF_TEMPLATES.get_template("fail_issue_created.md")

        post_md = template.render(
            project_id=project_id,
            gh=gh,
            peers=EVALUATORS,
            sub_url=SUB_URL,
            raw_url=RAW_URL,
            check_message=ISSUE_STATUS.message.item(),
        )

        post_file = op.join(PF_DIR, "assignments", f"{gh}_issue{gh_issue_num}.md")

        with open(post_file, "w") as f:
            f.write(post_md)

    if dry_run:
        return 0

    for gh in STUDENTS:
        click.echo(f"Assigning Peer Feedback for {gh}'s MP#0{project_id}")
        post_glob = glob(op.join(PF_DIR, "assignments", f"{gh}_issue*.md"))

        if len(post_glob) != 1:
            raise click.ClickException(f"Cannot find unique PF assignment script for {gh}")

        post_file = post_glob[0]

        with open(post_file, "r") as f:
            post_md = f.read()

        post_file_short = op.basename(post_file)

        gh_issue_num = int(re.search("_issue([0-9]+)\\.md$", post_file_short).group(1))

        # Directory with files indicating a successful post
        confirm_dir = op.join(PF_DIR, "confirms")
        os.makedirs(confirm_dir, exist_ok=True)

        # Check to see if issue has already been posted
        confirm_file = op.join(confirm_dir, f"{gh}_mp{project_id}_GITHUBSUCCESS")
        if op.exists(confirm_file):
            click.echo(f"Peer Feedback already assigned for {gh}'s MP#0{project_id}")
            continue  # If we find something that matches, move to next student

        # Else make a post
        if gh_issue_num:
            resp = gh_issue_comment(gh_issue_num, post_md)
            if resp.ok:
                with open(confirm_file, "w") as f:
                    f.write(
                        f"Successfully posted as {datetime.now().astimezone().strftime('%Y-%m-%dT%H:%M:%S_%Z')}"
                    )
                click.echo(
                    f"Peer Feedback successfully assigned for {gh}'s MP#0{project_id}"
                )
            else:
                raise click.ClickException(f"Could not post issue for {gh} at #{gh_issue_num}")
        else:
            title = f"MP #0{project_id} Peer Feedback for {gh} [INSTRUCTOR OPENED]"
            resp = gh_issue_create(title, post_md)
            if resp.ok:
                with open(confirm_file, "w") as f:
                    f.write(
                        f"Successfully posted as {datetime.now().astimezone().strftime('%Y-%m-%dT%H:%M:%S_%Z')}"
                    )
                click.echo(
                    f"Peer Feedback successfully assigned for {gh}'s MP#0{project_id}"
                )
                new_issue_num = int(resp.json()["number"])
                new_file = post_file.replace("issue0", f"issue{new_issue_num}")
                os.rename(post_file, new_file)
            else:
                raise click.ClickException(f"Could not post issue for {gh} at #{gh_issue_num}")


@cache
def _peer_feedback_collect_file(project_id):
    fname = op.join(course_dir(), f"mp0{project_id}", "COLLECTED_PEER_FEEDBACK.json")

    if not op.exists(fname):
        Path(fname).touch(exist_ok=True)

    return fname


@cache
def _peer_feedback_meta_file(project_id):
    fname = op.join(course_dir(), f"mp0{project_id}", "COLLECTED_META_REVIEW.json")

    if not op.exists(fname):
        Path(fname).touch(exist_ok=True)

    return fname

@cache
def grade_dir(project_id):
    dirname = op.join(course_dir(), f"mp0{project_id}", "grades")

    os.makedirs(dirname, exist_ok=True)

    return dirname

@cache
def meta_dir(project_id):
    dirname = op.join(course_dir(), f"mp0{project_id}", "meta")

    os.makedirs(dirname, exist_ok=True)

    return dirname

@peer.command(name="verify")
@click.option(
    "-N",
    "--number",
    "project_id",
    help="Mini-project to process peer feedback",
    prompt="Which mini-project to collect peer feedback for?",
    type=click.IntRange(min=0, max=4),
)
@click.option(
    "--use-existing",
    "rearchive",
    is_flag=True,
    default=True,
    help="Skip archiving and use cached issue comments",
)
@click.option(
    "--dry-run", "dry_run", help="Skip posting to GitHub", default=False, is_flag=True
)
def peer_verify(project_id, rearchive, dry_run):
    """Confirm peer feedback has been appropriately formatted
    
    Check peer feedback comments for formatting and post to GitHub"""
    if rearchive:
        _mini_archive(project_id, [], skip_pdf=True, archive_submissions=False)
        
    PF_MAPPING = _peer_assignment_mapping(project_id)
    PF_ASSIGNMENT_DIR = op.join(course_dir(), f"mp0{project_id}", "assignments")
    
    PF_ASSIGNMENT_FILES = [op.join(PF_ASSIGNMENT_DIR, fname) for fname in os.listdir(PF_ASSIGNMENT_DIR)]
    
    PF_ASSIGNMENT_COMMENTER = {}
    PF_ASSIGNMENT_COMMENTEE = {}
    
    ALL_PF = []
    PF_BY_EVALUATOR = defaultdict(list)
    
    for pf_file in os.listdir(PF_ASSIGNMENT_DIR):
        submittor, issue_num = re.match('(.*)_issue(\d+).md', pf_file).groups()

        with open(op.join(PF_ASSIGNMENT_DIR, pf_file), "r") as f:
            pf_text = f.read()

        potential_evaluators = PF_MAPPING[submittor]

        for evaluator in potential_evaluators:
            if evaluator in pf_text:
                pf = PeerFeedback(submittor, evaluator, project_id)
                ALL_PF.append(pf)
                PF_BY_EVALUATOR[evaluator].append(pf)
    
    STUDENTS_COMPLETED = [k for k, V in PF_BY_EVALUATOR.items() if all(v.ok for v in V)]
    STUDENTS_ALL_MISSING = [k for k, V in PF_BY_EVALUATOR.items() if all(v.missing for v in V)]
    
    STUDENTS_UNIFORM = STUDENTS_COMPLETED + STUDENTS_ALL_MISSING

    click.echo("--------")    
    if STUDENTS_COMPLETED: 
        click.echo(f"The following {len(STUDENTS_COMPLETED)} students have completed all peer feedback properly:")
        for ix, s in enumerate(STUDENTS_COMPLETED, start=1):
            click.echo(f"- {ix:02g}. {s}")
        click.echo("--------")
        
    if STUDENTS_ALL_MISSING:
        click.echo(f"The following {len(STUDENTS_ALL_MISSING)} students not started peer feedback:")
        for ix, s in enumerate(STUDENTS_ALL_MISSING, start=1):
            click.echo(f"- {ix:02g}. {s}")
        click.echo("--------")
        
    if len(STUDENTS_UNIFORM) != len(PF_BY_EVALUATOR):
        click.echo(f"The following {len(PF_BY_EVALUATOR) - len(STUDENTS_UNIFORM)} students have additional work to do:")
        
    for student, feedbacks in PF_BY_EVALUATOR.items():
        if student not in STUDENTS_UNIFORM: 
            proper_submittors   = [" [✓] " + f.submittor for f in feedbacks if f.ok]
            missing_submittors  = [" [M] " + f.submittor for f in feedbacks if f.missing]
            improper_submittors = [" [✗] " + f.submittor for f in feedbacks if f.improper]
 
            status_string = "".join(missing_submittors + improper_submittors + proper_submittors)
            
            n_ok = len(proper_submittors)
            n_all = len(feedbacks)
            click.echo(f"- {student} ({n_all - n_ok}/{n_all}):{status_string}")
            
    if len(STUDENTS_UNIFORM) != len(PF_BY_EVALUATOR):
        click.echo(" [✓] = Submitted with proper formatting")
        click.echo(" [✗] = Submitted with improper formatting")
        click.echo(" [M] = Missing submission")
        
    click.echo("---------")
    
    if dry_run: 
        return
    
    click.echo("GIT HUB POSTING NOT YET IMPLEMENTED")
    raise click.Abort()
    
@peer.command(name="collect")
@click.option(
    "-N",
    "--number",
    "project_id",
    help="Mini-project to process peer feedback",
    prompt="Which mini-project to collect peer feedback for?",
    type=click.IntRange(min=0, max=4),
)
@click.option(
    "--use-existing",
    "rearchive",
    is_flag=True,
    default=True,
    help="Skip archiving and use cached issue comments",
)
@click.option("--skip-pdf", is_flag=True, default=False, help="Skip PDF archiving")
@click.option(
    "-F",
    "--force",
    is_flag=True,
    default=False,
    help="Force re-evaluation of peer feedback.",
)
@click.option(
    "-g",
    "--github",
    multiple=True,
    help="GitHub ID to archive. Can be given multiple times. If blank, all active students in roster.",
)
def peer_collect(project_id, rearchive, skip_pdf, force, github):
    """Collect all peer feedback in a standardized format

    After the peer feedback window ends, this function will parse all GH
    issue comments to collect students' peer feedback. In theory, this is
    fully automatable, but students are bad at following instruction so this
    function will prompt for clarification repeatedly as it runs. This function
    saves its output as it goes so it is safe to terminate mid-execution and
    resume later. Run with '--force' to force regrading from the beginning.

    TODO: Add support for the -g flag to only process certain students."""
    if rearchive:
        _mini_archive(project_id, [], skip_pdf)

    ROSTER = current_roster()
    ALL_STUDENTS = set(ROSTER["github"])
    PF_MAPPING = _peer_assignment_mapping(project_id)

    PEER_FEEDBACK_SKELETON = {
        "scores": {
            "Written Communication": nan,
            "Project Skeleton": nan,
            "Formatting & Display": nan,
            "Code Quality": nan,
            "Data Preparation": nan,
            "Extra Credit": nan,
        },
        "comments": {
            "Written Communication": nan,
            "Project Skeleton": nan,
            "Formatting & Display": nan,
            "Code Quality": nan,
            "Data Preparation": nan,
            "Extra Credit": nan,
        },
        "posts": nan,
        "formatted_properly": nan,
    }

    pf_file = _peer_feedback_collect_file(project_id)

    with open(pf_file, "r") as f:
        try:
            ALL_PEER_FEEDBACK = json.loads(f.read())
            
            if not ALL_PEER_FEEDBACK:
                raise ValueError # Bail to make new feedback file
        except ValueError:
            ALL_PEER_FEEDBACK = {
                s: {vv: dcopy(PEER_FEEDBACK_SKELETON) for vv in v}
                for s, v in PF_MAPPING.items()
            }

    ALL_ISSUES_CONTENTS = load_issues()
    
    if not github: 
        STUDENT_LIST = ALL_PEER_FEEDBACK.keys()
    else: 
        STUDENT_LIST = github

    for student in STUDENT_LIST:
        if "issue_num" in ALL_PEER_FEEDBACK[student]:
            if not force:
                continue

        STUDENT_ISSUES = [
            c for c in ALL_ISSUES_CONTENTS if student.lower() in c["title"].lower()
        ]
        STUDENT_ISSUES.sort(key=lambda c: c["number"])

        num_str = f"#0{project_id}"

        RELEVANT_ISSUES = [s for s in STUDENT_ISSUES if num_str in s["title"]]

        if not RELEVANT_ISSUES:
            click.echo(
                f"I could not find an issue for {student} with '{num_str}' in the title."
            )
            click.echo("Please select the relevant issue from the choices below.")
            click.echo("If you want to see all issues, press 0.")

            for s in STUDENT_ISSUES:
                click.echo(f"- {s['number']}. Title: {s['title']}")

            issue_num = click.prompt(
                "Select the issue to use or press 0.",
                type=click.Choice([str(s["number"]) for s in STUDENT_ISSUES] + ["0"]),
            )

            try:
                issue_num = int(issue_num)
            except ValueError:
                click.echo(
                    "I could not interpret your input as an issue number. Interpreting as 0."
                )
                issue_num = 0

            if issue_num:
                KEY_ISSUE = [r for r in STUDENT_ISSUES if r["number"] == issue_num][0]
            else:
                click.echo(
                    "Please select from all issues. If no issue is appropriate, press 0."
                )
                for i in ALL_ISSUES_CONTENTS:
                    click.echo(f"- {i['number']}. Title: {i['title']}")

                issue_num = click.prompt(
                    "Select the issue to use or press 0.",
                    type=click.Choice(
                        [str(i["number"]) for i in ALL_ISSUES_CONTENTS] + ["0"]
                    ),
                )

                try:
                    issue_num = int(issue_num)
                except ValueError:
                    click.echo(
                        "I could not interpret your input as an issue number. Interpreting as 0."
                    )
                    issue_num = 0

            if not issue_num:
                continue  # Go to next student

            KEY_ISSUE = [i for i in ALL_ISSUES_CONTENTS if i["number"] == issue_num][0]

        elif len(RELEVANT_ISSUES) > 1:
            click.echo(
                f"I found multiple issue for {student} with '{num_str}' in the title."
            )
            click.echo("Please select the relevant issue from the choices below.")

            for r in RELEVANT_ISSUES:
                click.echo(f"- {r['number']}. Title: {r['title']}")

            issue_num = click.prompt(
                "Select the issue to use.",
                type=click.Choice([str(r["number"]) for r in RELEVANT_ISSUES]),
            )

            try:
                issue_num = int(issue_num)
            except ValueError:
                raise click.ClickException("I could not interpret your input as an issue number")

            KEY_ISSUE = [r for r in RELEVANT_ISSUES if r["number"] == issue_num][0]
        else:
            KEY_ISSUE = RELEVANT_ISSUES[0]
            
        EVALUATORS = ALL_STUDENTS.intersection(ALL_PEER_FEEDBACK[student].keys())

        for evaluator in EVALUATORS:
            current_posts = ALL_PEER_FEEDBACK[student][evaluator]["posts"]
            has_posts = current_posts and not is_nan(current_posts)
            
            if has_posts and not force:
                continue

            POSTS = "\n----NEW POST----\n".join(
                [
                    text
                    for author, text in KEY_ISSUE["comments"]
                    if author.lower() == evaluator.lower()
                ]
            )

            if not POSTS:
                ALL_PEER_FEEDBACK[student][evaluator]["posts"] = POSTS
                continue

            ALL_FORMATTING = True
            for k in ALL_PEER_FEEDBACK[student][evaluator]["scores"].keys():
                pattern = k + "[:][ ]+(\\d{1,2})"
                match = re.search(pattern, POSTS)

                if match is not None:
                    try:
                        score = int(match.group(1))
                    except ValueError:
                        ALL_FORMATTING = False
                        click.clear()
                        click.echo(f"I was unable to locate a score for '{k}'")
                        click.echo(
                            f"What score should be given to {student}, based on these comments:\n----"
                        )
                        click.echo(POSTS)
                        click.echo("----\n")
                        score = click.prompt(
                            f"Enter a score 0-10 for '{k}' or leave blank to keep NaN",
                            type=int,
                            default=-1,
                        )

                        if score < 0:
                            score = nan

                else:
                    ALL_FORMATTING = False
                    click.clear()
                    click.echo(f"I was unable to locate a score for '{k}'")
                    click.echo(
                        f"What score should be given to {student}, based on these comments:\n----"
                    )
                    click.echo(POSTS)
                    click.echo("----\n")
                    score = click.prompt(
                        f"Enter a score 0-10 for '{k}' or leave blank to keep NaN",
                        type=int,
                        default=nan,
                    )

                ALL_PEER_FEEDBACK[student][evaluator]["scores"][k] = score

            for k in ALL_PEER_FEEDBACK[student][evaluator]["comments"].keys():
                pattern = k + "[ \n]+(.*)[\n]?"
                match = re.search(pattern, POSTS)

                if match is not None:
                    comment = match.group(1)
                else:
                    ALL_FORMATTING = False
                    HEADER = f"""
                    I was unable to extract comments for '{k}'. Please edit
                    this file and leave only the comments on that topic.\n------\n"""
                    SOURCE = HEADER + POSTS
                    comment = click.edit(text=SOURCE, editor="/usr/bin/nano")

                    if not comment:
                        comment = ""

                ALL_PEER_FEEDBACK[student][evaluator]["comments"][k] = comment.strip()

            ALL_PEER_FEEDBACK[student][evaluator]["formatted_properly"] = ALL_FORMATTING
            ALL_PEER_FEEDBACK[student][evaluator]["posts"] = POSTS

            with open(pf_file, "w") as f:
                f.write(json.dumps(ALL_PEER_FEEDBACK, indent=2))

        # Save the issue number for later just in case
        ALL_PEER_FEEDBACK[student]["issue_num"] = KEY_ISSUE["number"]
        ALL_PEER_FEEDBACK[student]["submission_penalty"] = (
            "INSTRUCTOR" in KEY_ISSUE["title"]
        )

    with open(pf_file, "w") as f:
        f.write(json.dumps(ALL_PEER_FEEDBACK, indent=2))

    click.echo(f"All peer feedback processed for MP#0{project_id}")
    click.echo("You may now run 'peer grade' to compute actual grades")


@peer.command(name="grade")
@click.option(
    "-N",
    "--number",
    "project_id",
    help="Mini-Project to grade",
    prompt="Which mini-project to grade using peer feedback?",
    type=click.IntRange(min=0, max=4),
)
@click.option(
    "--max-extra-credit", 
    help="Cap extra credit at certain amount; set to 0 for no cap.",
    prompt="What amount should extra credit be capped at? Set 0 for no cap.",
    type=click.IntRange(min=0, max=10),
)
def peer_grade(project_id, max_extra_credit):
    """Consolidate collected peer feedback to assign grades

    After running 'collect', this function will parse the peer feedback
    comments and create text files summarizing feedback for each student.
    The instructor must then upload these to Brightspace to return them
    to the students. This function is very fast and can be safely re-run."""
    pf_file = _peer_feedback_collect_file(project_id)

    ROSTER = current_roster()

    with open(pf_file, "r") as f:
        try:
            ALL_PEER_FEEDBACK = json.loads(f.read() or '{}')
        except ValueError:
            raise click.ClickException("Feedback file appears to be empty. Run 'peer collect' first.")

    template = Environment(
        loader=FileSystemLoader("_cissoid/templates"), autoescape=select_autoescape()
    ).get_template("pf_grade_for_brightspace.md")

    with click.progressbar(ALL_PEER_FEEDBACK.items()) as bar:
        for student, feedback in bar:
            real_name = ROSTER[ROSTER["github"] == student]["name"].item()
            safe_name = real_name.lower().replace(" ", "_")
            evaluators = [e for e in feedback.keys()]

            try:
                penalty = feedback["submission_penalty"]
            except KeyError:
                penalty = click.confirm(
                    f"Should a submission penalty be applied to {student} on MP#0{project_id}?"
                )

            try:
                issue_num = feedback["issue_num"]
            except KeyError:
                click.echo(
                    f"I somehow lost the issue number for {student} on MP#0{project_id}."
                )
                issue_num = click.prompt("What issue number should I use?", type=int)

            CATEGORIES = [
                "Written Communication",
                "Project Skeleton",
                "Formatting & Display",
                "Code Quality",
                "Data Preparation",
                "Extra Credit",
            ]

            SCORE_DICT = {c: [] for c in CATEGORIES}
            COMMENTS_DICT = {c: [] for c in CATEGORIES}

            for evaluator in evaluators:
                if evaluator in ["submission_penalty", "issue_num"]:
                    continue
                
                e_feedback = feedback[evaluator]

                for c in CATEGORIES:
                    try:
                        e_feedback["scores"][c]
                    except TypeError:
                        import pdb; pdb.set_trace()

                    if is_nan(e_feedback["scores"][c]):
                        continue
                    
                    score = e_feedback["scores"][c]
                    comment = e_feedback["comments"][c]
                    
                    if max_extra_credit and c == "Extra Credit":
                        score = min(score, max_extra_credit)

                    SCORE_DICT[c].append(score)
                    COMMENTS_DICT[c].append((evaluator, comment))

            try:
                SCORES = {k: median(v) if v else nan for k, v in SCORE_DICT.items()}
                TOTAL = sum(SCORES.values())
            except:
                import pdb; pdb.set_trace()

            if penalty:
                TOTAL = TOTAL - 5

            if TOTAL < 0:
                TOTAL = 0

            grade_text = template.render(
                project_id=project_id,
                categories=CATEGORIES,
                scores=SCORES,
                scores_dict=SCORE_DICT,
                comments=COMMENTS_DICT,
                name=real_name,
                total=TOTAL,
                penalty=penalty,
                course_repo = course_repo(),
                course_dir=course_dir(),
                issue_num=issue_num,
            )

            grade_file = op.join(grade_dir(project_id), f"{safe_name}.txt")

            with open(grade_file, "w") as f:
                f.write(grade_text)


@peer.command(name="meta")
@click.option(
    "-N",
    "--number",
    "project_id",
    prompt="Which mini-project to meta-review peer feedback for?",
    type=click.IntRange(min=0, max=4),
)
@click.option(
    "--use-existing",
    "rearchive",
    is_flag=True,
    default=True,
    help="Skip archiving and use cached issue comments",
)
@click.option(
    "--skip-pdf", 
    is_flag=True, 
    default=False, 
    help="Skip PDF archiving"
)
@click.option(
    "-F",
    "--force",
    is_flag=True,
    default=False,
    help="Force re-evaluation of peer feedback."
)
def peer_meta(project_id, rearchive, skip_pdf, force):
    """Provide a Meta-Review of Peer-Feedback

    After collecting peer feedback, the course staff (instructor or TAs)
    need to assign a 'meta-review' score (0-10) on the quality of the peer
    feedback given. This function is designed to be used repeatedly and saves
    scores throughout evaluation. Run with '--force' to force regrading from 
    the beginning.

    TODO: Add support for the -g flag to only process certain students."""
    if rearchive:
        _mini_archive(project_id, [], skip_pdf)
        
    mp_str  = f"MP#0{project_id}"
    pf_file = _peer_feedback_collect_file(project_id)
    mg_file = _peer_feedback_meta_file(project_id)

    if not op.exists(pf_file):
        raise click.ClickException(f"Peer feedback file not found: run `peer collect -N {project_id}` to create feedback file at {pf_file}")

    with open(pf_file, "r") as f:
        try:
            ALL_PEER_FEEDBACK = json.loads(f.read())
        except ValueError:
            raise click.ClickException(f"Peer feedback appears to be empty. Run `peer collect -N {project_id}` to create feedback file at {pf_file}")
        
    NUM_PEER_FEEDBACK = sum([isinstance(v, dict) for f in ALL_PEER_FEEDBACK.values() for v in f.values()])

    ROSTER   = current_roster()
    STUDENTS = set(ROSTER["github"])
    
    with open(mg_file, "r") as f:
        try: 
            META_GRADES = json.loads(f.read())
        except json.JSONDecodeError:
            META_GRADES = {s: {} for s in STUDENTS}
    
    for submittor in STUDENTS: 
        FEEDBACK   = ALL_PEER_FEEDBACK[submittor]
        EVALUATORS = STUDENTS.intersection(FEEDBACK.keys())
        META_RUBRIC = None
        RUBRIC = None
        
        for evaluator in EVALUATORS:
            has_feedback = submittor in META_GRADES[evaluator]

            if has_feedback and not force:
                continue
                
            peer_comments = FEEDBACK[evaluator]["posts"]

            if not is_nan(peer_comments) and peer_comments:
                peer_comments = peer_comments.strip()
                SCORES_ASSIGNED = sum([len(v.keys()) for v in META_GRADES.values()])
                click.clear()
                click.echo(f"Meta {SCORES_ASSIGNED}/{NUM_PEER_FEEDBACK} ({SCORES_ASSIGNED / NUM_PEER_FEEDBACK:.1%}): {evaluator} left the following comments on {submittor}'s {mp_str}")
                click.echo("---===---")
                click.echo(peer_comments)
                click.echo("---===---")
                click.echo(f"Based on the above, what meta-review grade should be assigned to {evaluator}?")
            
                while True: 
                    score = click.prompt("Enter a score 0-10, r for the meta-review rubric, s for the PDF archive, i for the GitHub issue, or R for the original MP rubric:",
                                        type=click.Choice(SCORES_STR + ['r', 's', 'i', 'R', "h"]))
                                        
                    if score == "r":
                        if not META_RUBRIC:
                            META_RUBRIC = pd.read_html("https://michael-weylandt.com/STA9750/miniprojects.html")[0]
                        click.echo(META_RUBRIC)
                    elif score == "s":
                        latest_pdf = op.join(course_dir(), "latest", "pdfs", f"{submittor}_mp{project_id}.pdf")
                        if op.exists(latest_pdf):
                            subprocess.call(["open", latest_pdf])
                        else: 
                            import pdb; pdb.set_trace()
                    elif score == "R": 
                        if not RUBRIC:
                            RUBRIC = pd.read_html(f"https://michael-weylandt.com/STA9750/miniprojects/mini0{project_id}.html")[1]
                        click.echo(RUBRIC.T)
                    elif score == "i": 
                        webbrowser.open(f"https://github.com/michaelweylandt/{course_repo()}/issues/{FEEDBACK['issue_num']}")
                    elif score == "h": 
                        webbrowser.open(f"https:/{submittor}.github.io/{course_repo()}/mp0{project_id}.html")
                    else: 
                        score = int(score)
                        STANDARD_COMMENTS = [
                            "NO COMMENTS ON THIS TOPIC FOUND", 
                            "Missing submission - no penalty to evaluator.",
                            "This is really above and beyond - thank you for making the effort.",
                            "Great suggestions - really actionable and will certainly make a difference.",
                            "Comments are directionally correct, but would be better if there was more specificity.",
                            "Solid comments - but there's always some room for constructive cricitism even on the strongest projects, so think about if there's anything you would recommend improving upon.",
                            "Really useful comments. I think your scores are well-calibrated here, but try to be a bit more clear about _why_ you took off a few points in certain sections.",
                            "Good comments, focusing on just a few actionable items - thank you"
                        ]
                        
                        click.echo("Pre-canned comments:")
                        for n, txt in enumerate(STANDARD_COMMENTS):
                            click.echo(f"- {n}: {txt}")
                            
                        comment = click.prompt(f"Any comments for {evaluator}?", type=str)
                        
                        try: 
                            comment = STANDARD_COMMENTS[int(comment)]
                        except ValueError:
                            pass
                        
                        format_check = click.confirm("Was the submission appropriately formatted?", default=True)
                        
                        if not format_check:
                            comment += "\nPlease not that your submission was not formatted according to the provided template: https://michael-weylandt.com/STA9750/miniprojects.html#peer-feedback-template Please attempt to do so in the future or a penalty may be assessed."
                        
                        break
            else:
                score = 0
                comment = "NO PEER FEEDBACK IDENTIFIED. CONTACT INSTRUCTOR IF YOU BELIEVE PEER FEEDBACK SUBMISSION WAS MISSED."
            
            if 'issue_num' in FEEDBACK: 
                url = f"https://github.com/michaelweylandt/{course_repo()}/issues/{FEEDBACK['issue_num']}"
            else: 
                url = None

            META_GRADES[evaluator][submittor] = {
                "score": score, 
                "comment": comment, 
                "url": url
            }
            
            with open(mg_file, "w") as f:
                f.write(json.dumps(META_GRADES, indent=2))
            
    template = Environment(
        loader=FileSystemLoader("_cissoid/templates"), 
        autoescape=select_autoescape()
    ).get_template("meta_review.md")
    
    # Now consolidate feedback and write to file
    
    for student in STUDENTS: 
        feedback = META_GRADES[student]
        scores = [v['score'] for v in feedback.values()]
        real_name = ROSTER[ROSTER["github"] == student]["name"].item()
        safe_name = real_name.lower().replace(" ", "_")
        overall = sum(scores) / len(scores)
        
        grade_text = template.render(
            name = real_name,
            github = student, 
            project_id = project_id, 
            feedback = feedback, 
            overall = overall
            )
        grade_file = op.join(meta_dir(project_id), f"{safe_name}.txt")

        with open(grade_file, "w") as f:
            f.write(grade_text)

    click.echo(f"Meta review files written to {meta_dir(project_id)} can now be loaded to Brightspace.")



@course_manager.group()
def notify():
    """Helper functions to create reminder emails

    These work by creating a mailto URL that Outlook webmail can (supposedly)
    handle. This functionality is pretty sensitive and all emails should be
    reviewed before (manually) being sent."""


@notify.command(name="no-team")
def notify_no_team():
    "Email students who have not formed a STA 9750 course project team"

    ROSTER = current_roster()
    TEAMS = current_teams()
    BIG_ROSTER = pd.merge(
        ROSTER,
        TEAMS.rename(columns={"name": "team_name"}),
        how="left",
        left_on="project_team",
        right_on="number",
    )

    BIG_ROSTER = BIG_ROSTER[BIG_ROSTER["team_name"].isna()]

    BCC = BIG_ROSTER["email"].to_list()

    open_email(
        subject="STA 9750 - No Team Registered",
        bcc=BCC,
        body="Hello,\n\nIf you are receiving this email, it means I have not yet registered you on a team for your STA 9750 course project.\n\nPlease register a team with the instructor as soon as possible. See https://michael-weylandt.com/STA9750/project.html for details.",
    )


@notify.command(name="pf-assigned")
@click.option(
    "-N",
    "--number",
    "project_id",
    prompt="Which mini-project to notify peer feedback for?",
    type=click.IntRange(min=0, max=4),
)
def notify_pf_assigned(project_id):
    PF_MAPPING = get_pf_mapping(project_id)

    template = Environment(
        loader=FileSystemLoader("_cissoid/templates"), autoescape=select_autoescape()
    ).get_template("pf_assignment_email.md")

    for k, assignments in PF_MAPPING.items():
        name, github, email = k

        body = template.render(
            name=name, gh=github, project_id=project_id, assignments=assignments
        )

        open_email(
            to=email,
            body=body,
            flag_auto=False,
            subject=f"STA9750 MP#0{project_id} Peer Feedback Assignments for {github}",
        )


if __name__ == "__main__":
    course_manager()
